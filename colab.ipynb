{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3xqKJFza/hW7oTVg+Aelv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimheeseo/LSCNS/blob/main/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.preform.py**"
      ],
      "metadata": {
        "id": "-FOs6J0ENNOR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4YqYxZcjNMyb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "def run_preform(choice, input_excel=\"ab.xlsx\", desktop_path=None):\n",
        "    \"\"\"\n",
        "    choice: \"1\" or \"2\"\n",
        "    input_excel: ab.xlsx (default)\n",
        "    desktop_path: ì‚¬ìš©ì ë°”íƒ•í™”ë©´ ê²½ë¡œ (default: í˜„ì¬ ì‚¬ìš©ì)\n",
        "    \"\"\"\n",
        "    if desktop_path is None:\n",
        "        desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        folder_name = \"month_rit_number\"\n",
        "        column_title = \"rit_no\"\n",
        "        prefix_length = 3\n",
        "    elif choice == \"2\":\n",
        "        folder_name = \"month_resin_type\"\n",
        "        column_title = \"resin_type\"\n",
        "        prefix_length = 1\n",
        "    else:\n",
        "        raise ValueError(\"ì˜ëª»ëœ choice ê°’ì…ë‹ˆë‹¤. 1 ë˜ëŠ” 2ë§Œ í—ˆìš©.\")\n",
        "\n",
        "    folder_path = os.path.join(desktop_path, folder_name)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    file_path = os.path.join(desktop_path, input_excel)\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"ì…ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}\")\n",
        "\n",
        "    df = pd.read_excel(file_path, header=None, engine='openpyxl')\n",
        "    df = df.drop_duplicates(subset=1).reset_index(drop=True)  # rit_no ì¤‘ë³µ ì œê±°\n",
        "    rows, _ = df.shape\n",
        "\n",
        "    # ì›”ë³„ ë°ì´í„° ë° ì¹´ìš´í„° ì´ˆê¸°í™”\n",
        "    month_data = {f'mon_{str(m).zfill(2)}': [] for m in range(1, 13)}\n",
        "    month_count = {f'mon_{str(m).zfill(2)}': Counter() for m in range(1, 13)}\n",
        "\n",
        "    for col in range(rows):\n",
        "        cell_value = str(df.iloc[col, 2])\n",
        "        if cell_value.startswith(\"2025\") and len(cell_value) >= 6:\n",
        "            month = cell_value[4:6]\n",
        "            key = f'mon_{month}'\n",
        "            if key in month_data:\n",
        "                if column_title == 'rit_no':\n",
        "                    value_main = str(df.iloc[col, 1])\n",
        "                    value_work = str(df.iloc[col, 3])\n",
        "                    prefix = value_main[:prefix_length]\n",
        "                else:\n",
        "                    value_main = str(df.iloc[col, 4])\n",
        "                    value_work = str(df.iloc[col, 3])\n",
        "                    prefix = value_main[:prefix_length]\n",
        "                month_data[key].append([value_main, value_work])\n",
        "                month_count[key][prefix] += 1\n",
        "\n",
        "    # ìš”ì•½ ì •ë³´\n",
        "    summary_lines = []\n",
        "    summary_lines.append(f\"ğŸ“Š {column_title} ì›”ë³„ ë¶„í¬ ìš”ì•½:\\n\")\n",
        "    for month in sorted(month_count.keys()):\n",
        "        counts = month_count[month]\n",
        "        if counts:\n",
        "            summary_lines.append(f\"â–¶ {month}:\")\n",
        "            for prefix, cnt in counts.items():\n",
        "                summary_lines.append(f\"  - {prefix}: {cnt}ê°œ\")\n",
        "        else:\n",
        "            summary_lines.append(f\"â–¶ {month}: ì—†ìŒ\")\n",
        "\n",
        "    output_path = os.path.join(folder_path, f\"mon_split_{column_title}.xlsx\")\n",
        "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
        "        df_summary = pd.DataFrame(summary_lines, columns=[f\"{column_title}_summary\"])\n",
        "        df_summary.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "        for month, data in month_data.items():\n",
        "            if data:\n",
        "                df_month = pd.DataFrame(data, columns=[column_title, \"work_time\"])\n",
        "            else:\n",
        "                df_month = pd.DataFrame(columns=[column_title, \"work_time\"])\n",
        "            df_month.to_excel(writer, sheet_name=month, index=False)\n",
        "\n",
        "    return output_path, summary_lines"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.grouping.py**"
      ],
      "metadata": {
        "id": "SR7_NT_RNacx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def run_grouping(input_folder, output_base_folder):\n",
        "    \"\"\"\n",
        "    input_folder: 'grouped_by_prefix'\n",
        "    output_base_folder: 'grouped_by_prefix_split'\n",
        "    \"\"\"\n",
        "    os.makedirs(output_base_folder, exist_ok=True)\n",
        "    results = []\n",
        "    for file in os.listdir(input_folder):\n",
        "        if not file.endswith(\".xlsx\"):\n",
        "            continue\n",
        "        file_path = os.path.join(input_folder, file)\n",
        "        prefix = os.path.splitext(file)[0]\n",
        "\n",
        "        df = pd.read_excel(file_path, header=None)\n",
        "        header_row = df.iloc[[0]]\n",
        "        df_body = df.iloc[1:].reset_index(drop=True)\n",
        "\n",
        "        if df_body.shape[1] <= 3:\n",
        "            print(f\"âš  '{file}'ëŠ” 4ë²ˆì§¸ ì—´ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
        "            continue\n",
        "\n",
        "        df_body['__preform__'] = df_body[3].astype(str)\n",
        "        unique_preforms = df_body['__preform__'].unique()\n",
        "\n",
        "        output_folder = os.path.join(output_base_folder, prefix)\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "        for val in unique_preforms:\n",
        "            group = df_body[df_body['__preform__'] == val].drop(columns='__preform__')\n",
        "            group = group.replace(\"0\", \"\")\n",
        "            result_df = pd.concat([header_row, group], ignore_index=True)\n",
        "            save_path = os.path.join(output_folder, f\"{val}.xlsx\")\n",
        "            result_df.to_excel(save_path, index=False, header=False)\n",
        "            results.append(save_path)\n",
        "        print(f\"âœ… '{file}' ì²˜ë¦¬ ì™„ë£Œ â†’ {len(unique_preforms)}ê°œ íŒŒì¼ ì €ì¥ë¨\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "dvQws6mENalh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.classification.py**"
      ],
      "metadata": {
        "id": "jtuqlA-4NarK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def normalize_prefix(user_prefix):\n",
        "    return user_prefix.upper().replace(\"O\", \"0\")\n",
        "\n",
        "def run_classification(prefix_list, input_excel=\"alls.xlsx\", output_dir=\"grouped_by_prefix\"):\n",
        "    \"\"\"\n",
        "    prefix_list: [\"20M\", \"L0E\", ...] (ì´ë¯¸ ì •ê·œí™”ëœ ìƒíƒœë¡œ ì „ë‹¬ ê¶Œì¥)\n",
        "    input_excel: ì—‘ì…€ ì›ë³¸ íŒŒì¼ëª…\n",
        "    output_dir: ê²°ê³¼ í´ë”ëª…\n",
        "    \"\"\"\n",
        "    preform_prefix_list = [normalize_prefix(p) for p in prefix_list]\n",
        "    if not preform_prefix_list:\n",
        "        raise ValueError(\"ì…ë ¥ëœ í”„ë¦¬í¼ ì ‘ë‘ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    if not os.path.exists(input_excel):\n",
        "        raise FileNotFoundError(f\"ì…ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {input_excel}\")\n",
        "\n",
        "    df_all = pd.read_excel(input_excel, header=None)\n",
        "    header_row = df_all.iloc[[0]]\n",
        "    df_data = df_all.iloc[1:]\n",
        "\n",
        "    filtered_rows = []\n",
        "    for idx in range(len(df_data)):\n",
        "        val_col3 = df_data.iloc[idx, 2]\n",
        "        if isinstance(val_col3, str) and len(val_col3) >= 2:\n",
        "            if val_col3[-2] == '0':\n",
        "                filtered_rows.append(df_data.iloc[idx])\n",
        "\n",
        "    if not filtered_rows:\n",
        "        raise ValueError(\"ì¡°ê±´(3ë²ˆì§¸ ì—´ì˜ ë’¤ì—ì„œ ë‘ ë²ˆì§¸ ë¬¸ìê°€ '0')ì— ë§ëŠ” í–‰ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    df_filtered = pd.DataFrame(filtered_rows)\n",
        "    df_final = pd.concat([header_row, df_filtered], ignore_index=True)\n",
        "    df_final.to_excel(\"remove_not_zero.xlsx\", index=False, header=False)\n",
        "\n",
        "    df = pd.read_excel(\"remove_not_zero.xlsx\", header=None)\n",
        "    header = df.iloc[[0]]\n",
        "    df_body = df.iloc[1:]\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    saved_files = []\n",
        "\n",
        "    for prefix in preform_prefix_list:\n",
        "        group = df_body[df_body[3].astype(str).str[:3].str.upper() == prefix]\n",
        "        if not group.empty:\n",
        "            df_prefixed = pd.concat([header, group], ignore_index=True)\n",
        "            filename = os.path.join(output_dir, f\"{prefix}.xlsx\")\n",
        "            df_prefixed.to_excel(filename, index=False, header=False)\n",
        "            saved_files.append(filename)\n",
        "\n",
        "    return saved_files"
      ],
      "metadata": {
        "id": "Vby78JHQNavh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.average.py**"
      ],
      "metadata": {
        "id": "VIQsajWUNs-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def run_average(root_folder):\n",
        "    \"\"\"\n",
        "    root_folder: grouped_by_prefix_split\n",
        "    \"\"\"\n",
        "    save_count = 0\n",
        "    result_files = []\n",
        "    for subfolder in os.listdir(root_folder):\n",
        "        subfolder_path = os.path.join(root_folder, subfolder)\n",
        "        if not os.path.isdir(subfolder_path):\n",
        "            continue\n",
        "\n",
        "        average_rows = []\n",
        "        header_row = None\n",
        "\n",
        "        for file in os.listdir(subfolder_path):\n",
        "            if file.endswith(\".xlsx\") and not (file.endswith(\"_zerox.xlsx\") or file.endswith(\"_average.xlsx\")):\n",
        "                file_path = os.path.join(subfolder_path, file)\n",
        "                try:\n",
        "                    df = pd.read_excel(file_path, engine='openpyxl')\n",
        "                    df_zerox = df.where(df != 0, \"\")\n",
        "                    filename_wo_ext = os.path.splitext(file)[0]\n",
        "                    zerox_filename = f\"{filename_wo_ext}_zerox.xlsx\"\n",
        "                    zerox_path = os.path.join(subfolder_path, zerox_filename)\n",
        "                    df_zerox.to_excel(zerox_path, index=False)\n",
        "                    save_count += 1\n",
        "                    if save_count % 100 == 0:\n",
        "                        print(f\"âœ… ì´ {save_count}ê°œ íŒŒì¼ ì €ì¥ ì™„ë£Œ\")\n",
        "\n",
        "                    df_zerox = pd.read_excel(zerox_path, engine='openpyxl')\n",
        "                    col_4_name = df_zerox.columns[3]\n",
        "                    filtered_df = df_zerox[df_zerox[col_4_name].astype(str) == filename_wo_ext]\n",
        "\n",
        "                    sum_series = []\n",
        "                    count_series = []\n",
        "                    for col in filtered_df.columns:\n",
        "                        values = pd.to_numeric(filtered_df[col], errors='coerce')\n",
        "                        values_for_sum = values.fillna(0)\n",
        "                        values_for_count = values.notna().astype(int)\n",
        "                        sum_series.append(values_for_sum.sum())\n",
        "                        count_series.append(values_for_count.sum())\n",
        "\n",
        "                    avg_values = []\n",
        "                    for total, count in zip(sum_series, count_series):\n",
        "                        avg = round(total / count, 4) if count > 0 else \"\"\n",
        "                        avg_values.append(avg)\n",
        "\n",
        "                    average_row = pd.DataFrame([avg_values], columns=df_zerox.columns)\n",
        "                    average_row = average_row.astype(\"object\")\n",
        "                    average_row.iat[0, 1] = filename_wo_ext\n",
        "                    first_row = df_zerox.iloc[[0]]\n",
        "                    result_df = pd.concat([first_row, average_row], ignore_index=True)\n",
        "                    average_filename = f\"{filename_wo_ext}_average.xlsx\"\n",
        "                    average_path = os.path.join(subfolder_path, average_filename)\n",
        "                    result_df.to_excel(average_path, index=False)\n",
        "                except Exception as e:\n",
        "                    print(f\"âš ï¸ ì˜¤ë¥˜ ë°œìƒ ({file}): {e}\")\n",
        "\n",
        "        # í‰ê·  í–‰ë§Œ ëª¨ì•„ì„œ ìµœì¢… íŒŒì¼ ì €ì¥\n",
        "        for file in os.listdir(subfolder_path):\n",
        "            if file.endswith(\"_average.xlsx\"):\n",
        "                try:\n",
        "                    df_avg = pd.read_excel(os.path.join(subfolder_path, file), engine='openpyxl')\n",
        "                    if header_row is None:\n",
        "                        header_row = df_avg.iloc[[0]]\n",
        "                    last_row = df_avg.iloc[[-1]]\n",
        "                    average_rows.append(last_row)\n",
        "                except Exception as e:\n",
        "                    print(f\"âš ï¸ í‰ê·  íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({file}): {e}\")\n",
        "\n",
        "        if average_rows and header_row is not None:\n",
        "            final_df = pd.concat([header_row] + average_rows, ignore_index=True)\n",
        "            final_filename = f\"{subfolder}_final.xlsx\"\n",
        "            final_path = os.path.join(subfolder_path, final_filename)\n",
        "            final_df.to_excel(final_path, index=False)\n",
        "            result_files.append(final_path)\n",
        "            print(f\"ğŸ“¦ ìµœì¢… ìš”ì•½ ì €ì¥ ì™„ë£Œ: {final_filename}\")\n",
        "    return result_files"
      ],
      "metadata": {
        "id": "pa_pogTQNvVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.auto_analyzer.py**"
      ],
      "metadata": {
        "id": "h-K-bc4CNxFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def run_auto_analyzer(root_folder):\n",
        "    \"\"\"\n",
        "    root_folder: grouped_by_prefix_split\n",
        "    \"\"\"\n",
        "    # (ì¶œë ¥ ì—´ ì´ë¦„, final ì—‘ì…€ ì—´ ë²ˆí˜¸, ê³„ì‚°ì‹ lambda ë˜ëŠ” None, ê³±ì…ˆ ê³„ìˆ˜ ë˜ëŠ” None)\n",
        "    column_info = [\n",
        "        (\"spoolno2\", 1, None, None),\n",
        "        (\"OTDR length\", 9, None, None),\n",
        "        (\"Attenuation 1310 I/E\", 5, None, None),\n",
        "        (\"Attenuation 1310 O/E\", 6, None, None),\n",
        "        (\"Attenuation 1383 I/E\", 73, None, None),\n",
        "        (\"Attenuation 1383 O/E\", 74, None, None),\n",
        "        (\"Attenuation 1550 I/E\", 7, None, None),\n",
        "        (\"Attenuation 1550 O/E\", 8, None, None),\n",
        "        (\"Attenuation 1625 I/E\", 75, None, None),\n",
        "        (\"Attenuation 1625 O/E\", 76, None, None),\n",
        "        (\"MFD 1310nm I/E\", 12, None, None),\n",
        "        (\"MFD 1310nm O/E\", 13, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"Cutoff 2m I/E\", 14, None, None),\n",
        "        (\"Cutoff 2m O/E\", 15, None, None),\n",
        "        (\"Cutoff 22m\", 24, None, None),\n",
        "        (\"delta 2m-22m\", None, 'delta', None),\n",
        "        (\"Mac value\", None, 'mac', None),\n",
        "        (\"Clad Dia. I/E\", 16, None, None),\n",
        "        (\"Clad Dia. O/E\", 17, None, None),\n",
        "        (\"Clad Ovality I/E\", 18, None, None),\n",
        "        (\"Clad Ovality O/E\", 19, None, None),\n",
        "        (\"Core Ovality I/E\", 20, None, None),\n",
        "        (\"Core Ovality O/E\", 21, None, None),\n",
        "        (\"ECC I/E\", 22, None, None),\n",
        "        (\"ECC O/E\", 23, None, None),\n",
        "        (\"Zero Dispersion Wave.\", 30, None, None),\n",
        "        (\"dispslope at ZDW\", 31, None, None),\n",
        "        (\"Dispersion 1285\", 32, None, None),\n",
        "        (\"Dispersion 1290\", 33, None, None),\n",
        "        (\"Dispersion 1330\", 34, None, None),\n",
        "        (\"Dispersion 1550\", 35, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"PMD\", 37, None, None),\n",
        "        (\"R7.5mm 1t 1550\", 26, 'scale', 0.1),\n",
        "        (\"R7.5mm 1t 1625\", 69, 'scale', 0.1),\n",
        "        (\"R10mm 1t 1550\", 70, 'scale', 0.1),\n",
        "        (\"R10mm 1t 1625\", 71, 'scale', 0.1),\n",
        "        (\"R15mm 10t 1550\", 81, 'scale', 0.5),\n",
        "        (\"R15mm 10t 1625\", 82, 'scale', 0.5),\n",
        "    ]\n",
        "\n",
        "    for subfolder in os.listdir(root_folder):\n",
        "        subfolder_path = os.path.join(root_folder, subfolder)\n",
        "        if not os.path.isdir(subfolder_path):\n",
        "            continue\n",
        "\n",
        "        final_files = [f for f in os.listdir(subfolder_path) if f.endswith(\"final.xlsx\")]\n",
        "        if not final_files:\n",
        "            print(f\"âŒ '{subfolder}' í´ë”ì—ëŠ” final.xlsx íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            continue\n",
        "\n",
        "        final_path = os.path.join(subfolder_path, final_files[0])\n",
        "        try:\n",
        "            df = pd.read_excel(final_path, header=None, engine='openpyxl')\n",
        "            df_result = pd.DataFrame()\n",
        "            n_rows = len(df) - 2  # 3ë²ˆì§¸ ì¤„ë¶€í„° ì‹œì‘\n",
        "\n",
        "            for col_idx, (title, src_col, calc_type, factor) in enumerate(column_info):\n",
        "                df_result.loc[0, col_idx] = title  # ì²« í–‰ ì œëª©\n",
        "\n",
        "                if calc_type is None:\n",
        "                    if src_col is not None:\n",
        "                        col_values = df.iloc[2:, src_col].tolist()\n",
        "                        for row_idx, val in enumerate(col_values):\n",
        "                            df_result.loc[row_idx + 1, col_idx] = val\n",
        "                elif calc_type == 'delta':\n",
        "                    col_20 = df_result.iloc[1:, 19].astype(float)\n",
        "                    col_21 = df_result.iloc[1:, 20].astype(float)\n",
        "                    df_result.iloc[1:, col_idx] = (col_20 - col_21).round(4)\n",
        "                elif calc_type == 'mac':\n",
        "                    col_12 = pd.to_numeric(df_result.iloc[1:, 11], errors='coerce')\n",
        "                    col_19 = pd.to_numeric(df_result.iloc[1:, 18], errors='coerce')\n",
        "                    df_result.iloc[1:, col_idx] = ((col_12 / col_19) * 1000).round(2)\n",
        "                elif calc_type == 'scale':\n",
        "                    raw_values = df.iloc[2:, src_col]\n",
        "                    scaled_values = []\n",
        "                    for val in raw_values:\n",
        "                        try:\n",
        "                            scaled_values.append(round(float(val) * factor, 4))\n",
        "                        except:\n",
        "                            scaled_values.append(\"\")\n",
        "                    for row_idx, val in enumerate(scaled_values):\n",
        "                        df_result.loc[row_idx + 1, col_idx] = val\n",
        "\n",
        "            save_path = os.path.join(subfolder_path, f\"{subfolder}_final_result_report.xlsx\")\n",
        "            df_result.to_excel(save_path, index=False, header=False)\n",
        "            print(f\"âœ… ì €ì¥ ì™„ë£Œ: {save_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ ì˜¤ë¥˜ ë°œìƒ ({subfolder}): {e}\")"
      ],
      "metadata": {
        "id": "926vnwNINzRR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**main.py**"
      ],
      "metadata": {
        "id": "2GW53k4VN1bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from preform import run_preform\n",
        "from classification import run_classification\n",
        "from grouping import run_grouping\n",
        "from average import run_average\n",
        "from auto_analyzer import run_auto_analyzer\n",
        "\n",
        "def main():\n",
        "    # 1. ì²« ë²ˆì§¸ ìë™ ì…ë ¥\n",
        "    print(\"ì›”ë³„ ì–´ë–¤ ê°’ì„ ì¶”ì¶œí•  ê²ƒì…ë‹ˆê¹Œ?\\n1. rit_no\\n2. resin_type\")\n",
        "    time.sleep(2)\n",
        "    print(\"1ì´ ìë™ìœ¼ë¡œ ì…ë ¥ë©ë‹ˆë‹¤.\")\n",
        "    result_path_1, summary_1 = run_preform(\"1\")\n",
        "    print(\"\\n[1ë²ˆ ê²°ê³¼]\")\n",
        "    print(\"\\n\".join(summary_1))\n",
        "    print(f\"âœ”ï¸ preform ì™„ë£Œ: {result_path_1}\\n\")\n",
        "\n",
        "    # 2. ë‘ ë²ˆì§¸ ìë™ ì…ë ¥\n",
        "    time.sleep(2)\n",
        "    print(\"2ì´ ìë™ìœ¼ë¡œ ì…ë ¥ë©ë‹ˆë‹¤.\")\n",
        "    result_path_2, summary_2 = run_preform(\"2\")\n",
        "    print(\"\\n[2ë²ˆ ê²°ê³¼]\")\n",
        "    print(\"\\n\".join(summary_2))\n",
        "    print(f\"âœ”ï¸ preform ì™„ë£Œ: {result_path_2}\\n\")\n",
        "\n",
        "    # 3. ê´€ì‹¬ í”„ë¦¬í¼ ì ‘ë‘ì‚¬ ì…ë ¥\n",
        "    print(\"\\nê´€ì‹¬ í”„ë¦¬í¼ ì ‘ë‘ì‚¬ë¥¼ í•˜ë‚˜ì”© ì…ë ¥í•˜ì„¸ìš”. (ëë‚´ë ¤ë©´ 'a' ì…ë ¥)\")\n",
        "    prefixes = []\n",
        "    while True:\n",
        "        pf = input(\"â–¶ í”„ë¦¬í¼ ì…ë ¥: \").strip()\n",
        "        if pf.lower() == 'a':\n",
        "            break\n",
        "        if pf:\n",
        "            prefixes.append(pf)\n",
        "    if not prefixes:\n",
        "        print(\"â—ì…ë ¥ëœ í”„ë¦¬í¼ì´ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
        "\n",
        "    # 4. classification.py ì‹¤í–‰\n",
        "    print(\"\\n[2/5] classification.py ì‹¤í–‰ì¤‘...\")\n",
        "    classified_files = run_classification(prefixes)\n",
        "    print(f\"âœ”ï¸ classification ì™„ë£Œ: {len(classified_files)}ê°œ íŒŒì¼ ë¶„ë¥˜\")\n",
        "\n",
        "    # 5. grouping.py ì‹¤í–‰\n",
        "    print(\"\\n[3/5] grouping.py ì‹¤í–‰ì¤‘...\")\n",
        "    grouped_files = run_grouping(\"grouped_by_prefix\", \"grouped_by_prefix_split\")\n",
        "    print(f\"âœ”ï¸ grouping ì™„ë£Œ: {len(grouped_files)}ê°œ íŒŒì¼ ìƒì„±\")\n",
        "\n",
        "    # 6. average.py ì‹¤í–‰\n",
        "    print(\"\\n[4/5] average.py ì‹¤í–‰ì¤‘...\")\n",
        "    average_files = run_average(os.path.join(desktop_path, \"grouped_by_prefix_split\"))\n",
        "    print(f\"âœ”ï¸ average ì™„ë£Œ: {len(average_files)}ê°œ ìš”ì•½ íŒŒì¼ ìƒì„±\")\n",
        "\n",
        "    # 7. auto_analyzer.py ì‹¤í–‰\n",
        "    print(\"\\n[5/5] auto_analyzer.py ì‹¤í–‰ì¤‘...\")\n",
        "    run_auto_analyzer(os.path.join(desktop_path, \"grouped_by_prefix_split\"))\n",
        "    print(f\"âœ”ï¸ auto_analyzer ì™„ë£Œ\")\n",
        "\n",
        "    print(\"\\nğŸ‰ ì „ì²´ ìë™í™” íŒŒì´í”„ë¼ì¸ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "cxIs7T4bN4zQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}