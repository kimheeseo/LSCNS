{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3xqKJFza/hW7oTVg+Aelv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimheeseo/LSCNS/blob/main/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.preform.py**"
      ],
      "metadata": {
        "id": "-FOs6J0ENNOR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4YqYxZcjNMyb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "def run_preform(choice, input_excel=\"ab.xlsx\", desktop_path=None):\n",
        "    \"\"\"\n",
        "    choice: \"1\" or \"2\"\n",
        "    input_excel: ab.xlsx (default)\n",
        "    desktop_path: ÏÇ¨Ïö©Ïûê Î∞îÌÉïÌôîÎ©¥ Í≤ΩÎ°ú (default: ÌòÑÏû¨ ÏÇ¨Ïö©Ïûê)\n",
        "    \"\"\"\n",
        "    if desktop_path is None:\n",
        "        desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        folder_name = \"month_rit_number\"\n",
        "        column_title = \"rit_no\"\n",
        "        prefix_length = 3\n",
        "    elif choice == \"2\":\n",
        "        folder_name = \"month_resin_type\"\n",
        "        column_title = \"resin_type\"\n",
        "        prefix_length = 1\n",
        "    else:\n",
        "        raise ValueError(\"ÏûòÎ™ªÎêú choice Í∞íÏûÖÎãàÎã§. 1 ÎòêÎäî 2Îßå ÌóàÏö©.\")\n",
        "\n",
        "    folder_path = os.path.join(desktop_path, folder_name)\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    file_path = os.path.join(desktop_path, input_excel)\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"ÏûÖÎ†• ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§: {file_path}\")\n",
        "\n",
        "    df = pd.read_excel(file_path, header=None, engine='openpyxl')\n",
        "    df = df.drop_duplicates(subset=1).reset_index(drop=True)  # rit_no Ï§ëÎ≥µ Ï†úÍ±∞\n",
        "    rows, _ = df.shape\n",
        "\n",
        "    # ÏõîÎ≥Ñ Îç∞Ïù¥ÌÑ∞ Î∞è Ïπ¥Ïö¥ÌÑ∞ Ï¥àÍ∏∞Ìôî\n",
        "    month_data = {f'mon_{str(m).zfill(2)}': [] for m in range(1, 13)}\n",
        "    month_count = {f'mon_{str(m).zfill(2)}': Counter() for m in range(1, 13)}\n",
        "\n",
        "    for col in range(rows):\n",
        "        cell_value = str(df.iloc[col, 2])\n",
        "        if cell_value.startswith(\"2025\") and len(cell_value) >= 6:\n",
        "            month = cell_value[4:6]\n",
        "            key = f'mon_{month}'\n",
        "            if key in month_data:\n",
        "                if column_title == 'rit_no':\n",
        "                    value_main = str(df.iloc[col, 1])\n",
        "                    value_work = str(df.iloc[col, 3])\n",
        "                    prefix = value_main[:prefix_length]\n",
        "                else:\n",
        "                    value_main = str(df.iloc[col, 4])\n",
        "                    value_work = str(df.iloc[col, 3])\n",
        "                    prefix = value_main[:prefix_length]\n",
        "                month_data[key].append([value_main, value_work])\n",
        "                month_count[key][prefix] += 1\n",
        "\n",
        "    # ÏöîÏïΩ Ï†ïÎ≥¥\n",
        "    summary_lines = []\n",
        "    summary_lines.append(f\"üìä {column_title} ÏõîÎ≥Ñ Î∂ÑÌè¨ ÏöîÏïΩ:\\n\")\n",
        "    for month in sorted(month_count.keys()):\n",
        "        counts = month_count[month]\n",
        "        if counts:\n",
        "            summary_lines.append(f\"‚ñ∂ {month}:\")\n",
        "            for prefix, cnt in counts.items():\n",
        "                summary_lines.append(f\"  - {prefix}: {cnt}Í∞ú\")\n",
        "        else:\n",
        "            summary_lines.append(f\"‚ñ∂ {month}: ÏóÜÏùå\")\n",
        "\n",
        "    output_path = os.path.join(folder_path, f\"mon_split_{column_title}.xlsx\")\n",
        "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
        "        df_summary = pd.DataFrame(summary_lines, columns=[f\"{column_title}_summary\"])\n",
        "        df_summary.to_excel(writer, sheet_name=\"Summary\", index=False)\n",
        "        for month, data in month_data.items():\n",
        "            if data:\n",
        "                df_month = pd.DataFrame(data, columns=[column_title, \"work_time\"])\n",
        "            else:\n",
        "                df_month = pd.DataFrame(columns=[column_title, \"work_time\"])\n",
        "            df_month.to_excel(writer, sheet_name=month, index=False)\n",
        "\n",
        "    return output_path, summary_lines"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.grouping.py**"
      ],
      "metadata": {
        "id": "SR7_NT_RNacx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def run_grouping(input_folder, output_base_folder):\n",
        "    \"\"\"\n",
        "    input_folder: 'grouped_by_prefix'\n",
        "    output_base_folder: 'grouped_by_prefix_split'\n",
        "    \"\"\"\n",
        "    os.makedirs(output_base_folder, exist_ok=True)\n",
        "    results = []\n",
        "    for file in os.listdir(input_folder):\n",
        "        if not file.endswith(\".xlsx\"):\n",
        "            continue\n",
        "        file_path = os.path.join(input_folder, file)\n",
        "        prefix = os.path.splitext(file)[0]\n",
        "\n",
        "        df = pd.read_excel(file_path, header=None)\n",
        "        header_row = df.iloc[[0]]\n",
        "        df_body = df.iloc[1:].reset_index(drop=True)\n",
        "\n",
        "        if df_body.shape[1] <= 3:\n",
        "            print(f\"‚ö† '{file}'Îäî 4Î≤àÏß∏ Ïó¥Ïù¥ ÏóÜÏñ¥ Í±¥ÎÑàÎúÅÎãàÎã§.\")\n",
        "            continue\n",
        "\n",
        "        df_body['__preform__'] = df_body[3].astype(str)\n",
        "        unique_preforms = df_body['__preform__'].unique()\n",
        "\n",
        "        output_folder = os.path.join(output_base_folder, prefix)\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "        for val in unique_preforms:\n",
        "            group = df_body[df_body['__preform__'] == val].drop(columns='__preform__')\n",
        "            group = group.replace(\"0\", \"\")\n",
        "            result_df = pd.concat([header_row, group], ignore_index=True)\n",
        "            save_path = os.path.join(output_folder, f\"{val}.xlsx\")\n",
        "            result_df.to_excel(save_path, index=False, header=False)\n",
        "            results.append(save_path)\n",
        "        print(f\"‚úÖ '{file}' Ï≤òÎ¶¨ ÏôÑÎ£å ‚Üí {len(unique_preforms)}Í∞ú ÌååÏùº Ï†ÄÏû•Îê®\")\n",
        "    return results"
      ],
      "metadata": {
        "id": "dvQws6mENalh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.classification.py**"
      ],
      "metadata": {
        "id": "jtuqlA-4NarK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def normalize_prefix(user_prefix):\n",
        "    return user_prefix.upper().replace(\"O\", \"0\")\n",
        "\n",
        "def run_classification(prefix_list, input_excel=\"alls.xlsx\", output_dir=\"grouped_by_prefix\"):\n",
        "    \"\"\"\n",
        "    prefix_list: [\"20M\", \"L0E\", ...] (Ïù¥ÎØ∏ Ï†ïÍ∑úÌôîÎêú ÏÉÅÌÉúÎ°ú Ï†ÑÎã¨ Í∂åÏû•)\n",
        "    input_excel: ÏóëÏÖÄ ÏõêÎ≥∏ ÌååÏùºÎ™Ö\n",
        "    output_dir: Í≤∞Í≥º Ìè¥ÎçîÎ™Ö\n",
        "    \"\"\"\n",
        "    preform_prefix_list = [normalize_prefix(p) for p in prefix_list]\n",
        "    if not preform_prefix_list:\n",
        "        raise ValueError(\"ÏûÖÎ†•Îêú ÌîÑÎ¶¨Ìèº Ï†ëÎëêÏÇ¨Í∞Ä ÏóÜÏäµÎãàÎã§.\")\n",
        "\n",
        "    if not os.path.exists(input_excel):\n",
        "        raise FileNotFoundError(f\"ÏûÖÎ†• ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§: {input_excel}\")\n",
        "\n",
        "    df_all = pd.read_excel(input_excel, header=None)\n",
        "    header_row = df_all.iloc[[0]]\n",
        "    df_data = df_all.iloc[1:]\n",
        "\n",
        "    filtered_rows = []\n",
        "    for idx in range(len(df_data)):\n",
        "        val_col3 = df_data.iloc[idx, 2]\n",
        "        if isinstance(val_col3, str) and len(val_col3) >= 2:\n",
        "            if val_col3[-2] == '0':\n",
        "                filtered_rows.append(df_data.iloc[idx])\n",
        "\n",
        "    if not filtered_rows:\n",
        "        raise ValueError(\"Ï°∞Í±¥(3Î≤àÏß∏ Ïó¥Ïùò Îí§ÏóêÏÑú Îëê Î≤àÏß∏ Î¨∏ÏûêÍ∞Ä '0')Ïóê ÎßûÎäî ÌñâÏù¥ ÏóÜÏäµÎãàÎã§.\")\n",
        "\n",
        "    df_filtered = pd.DataFrame(filtered_rows)\n",
        "    df_final = pd.concat([header_row, df_filtered], ignore_index=True)\n",
        "    df_final.to_excel(\"remove_not_zero.xlsx\", index=False, header=False)\n",
        "\n",
        "    df = pd.read_excel(\"remove_not_zero.xlsx\", header=None)\n",
        "    header = df.iloc[[0]]\n",
        "    df_body = df.iloc[1:]\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    saved_files = []\n",
        "\n",
        "    for prefix in preform_prefix_list:\n",
        "        group = df_body[df_body[3].astype(str).str[:3].str.upper() == prefix]\n",
        "        if not group.empty:\n",
        "            df_prefixed = pd.concat([header, group], ignore_index=True)\n",
        "            filename = os.path.join(output_dir, f\"{prefix}.xlsx\")\n",
        "            df_prefixed.to_excel(filename, index=False, header=False)\n",
        "            saved_files.append(filename)\n",
        "\n",
        "    return saved_files"
      ],
      "metadata": {
        "id": "Vby78JHQNavh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.average.py**"
      ],
      "metadata": {
        "id": "VIQsajWUNs-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def run_average(root_folder):\n",
        "    \"\"\"\n",
        "    root_folder: grouped_by_prefix_split\n",
        "    \"\"\"\n",
        "    save_count = 0\n",
        "    result_files = []\n",
        "    for subfolder in os.listdir(root_folder):\n",
        "        subfolder_path = os.path.join(root_folder, subfolder)\n",
        "        if not os.path.isdir(subfolder_path):\n",
        "            continue\n",
        "\n",
        "        average_rows = []\n",
        "        header_row = None\n",
        "\n",
        "        for file in os.listdir(subfolder_path):\n",
        "            if file.endswith(\".xlsx\") and not (file.endswith(\"_zerox.xlsx\") or file.endswith(\"_average.xlsx\")):\n",
        "                file_path = os.path.join(subfolder_path, file)\n",
        "                try:\n",
        "                    df = pd.read_excel(file_path, engine='openpyxl')\n",
        "                    df_zerox = df.where(df != 0, \"\")\n",
        "                    filename_wo_ext = os.path.splitext(file)[0]\n",
        "                    zerox_filename = f\"{filename_wo_ext}_zerox.xlsx\"\n",
        "                    zerox_path = os.path.join(subfolder_path, zerox_filename)\n",
        "                    df_zerox.to_excel(zerox_path, index=False)\n",
        "                    save_count += 1\n",
        "                    if save_count % 100 == 0:\n",
        "                        print(f\"‚úÖ Ï¥ù {save_count}Í∞ú ÌååÏùº Ï†ÄÏû• ÏôÑÎ£å\")\n",
        "\n",
        "                    df_zerox = pd.read_excel(zerox_path, engine='openpyxl')\n",
        "                    col_4_name = df_zerox.columns[3]\n",
        "                    filtered_df = df_zerox[df_zerox[col_4_name].astype(str) == filename_wo_ext]\n",
        "\n",
        "                    sum_series = []\n",
        "                    count_series = []\n",
        "                    for col in filtered_df.columns:\n",
        "                        values = pd.to_numeric(filtered_df[col], errors='coerce')\n",
        "                        values_for_sum = values.fillna(0)\n",
        "                        values_for_count = values.notna().astype(int)\n",
        "                        sum_series.append(values_for_sum.sum())\n",
        "                        count_series.append(values_for_count.sum())\n",
        "\n",
        "                    avg_values = []\n",
        "                    for total, count in zip(sum_series, count_series):\n",
        "                        avg = round(total / count, 4) if count > 0 else \"\"\n",
        "                        avg_values.append(avg)\n",
        "\n",
        "                    average_row = pd.DataFrame([avg_values], columns=df_zerox.columns)\n",
        "                    average_row = average_row.astype(\"object\")\n",
        "                    average_row.iat[0, 1] = filename_wo_ext\n",
        "                    first_row = df_zerox.iloc[[0]]\n",
        "                    result_df = pd.concat([first_row, average_row], ignore_index=True)\n",
        "                    average_filename = f\"{filename_wo_ext}_average.xlsx\"\n",
        "                    average_path = os.path.join(subfolder_path, average_filename)\n",
        "                    result_df.to_excel(average_path, index=False)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è Ïò§Î•ò Î∞úÏÉù ({file}): {e}\")\n",
        "\n",
        "        # ÌèâÍ∑† ÌñâÎßå Î™®ÏïÑÏÑú ÏµúÏ¢Ö ÌååÏùº Ï†ÄÏû•\n",
        "        for file in os.listdir(subfolder_path):\n",
        "            if file.endswith(\"_average.xlsx\"):\n",
        "                try:\n",
        "                    df_avg = pd.read_excel(os.path.join(subfolder_path, file), engine='openpyxl')\n",
        "                    if header_row is None:\n",
        "                        header_row = df_avg.iloc[[0]]\n",
        "                    last_row = df_avg.iloc[[-1]]\n",
        "                    average_rows.append(last_row)\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è ÌèâÍ∑† ÌååÏùº Ï≤òÎ¶¨ Ïò§Î•ò ({file}): {e}\")\n",
        "\n",
        "        if average_rows and header_row is not None:\n",
        "            final_df = pd.concat([header_row] + average_rows, ignore_index=True)\n",
        "            final_filename = f\"{subfolder}_final.xlsx\"\n",
        "            final_path = os.path.join(subfolder_path, final_filename)\n",
        "            final_df.to_excel(final_path, index=False)\n",
        "            result_files.append(final_path)\n",
        "            print(f\"üì¶ ÏµúÏ¢Ö ÏöîÏïΩ Ï†ÄÏû• ÏôÑÎ£å: {final_filename}\")\n",
        "    return result_files"
      ],
      "metadata": {
        "id": "pa_pogTQNvVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.auto_analyzer.py**"
      ],
      "metadata": {
        "id": "h-K-bc4CNxFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def run_auto_analyzer(root_folder):\n",
        "    \"\"\"\n",
        "    root_folder: grouped_by_prefix_split\n",
        "    \"\"\"\n",
        "    # (Ï∂úÎ†• Ïó¥ Ïù¥Î¶Ñ, final ÏóëÏÖÄ Ïó¥ Î≤àÌò∏, Í≥ÑÏÇ∞Ïãù lambda ÎòêÎäî None, Í≥±ÏÖà Í≥ÑÏàò ÎòêÎäî None)\n",
        "    column_info = [\n",
        "        (\"spoolno2\", 1, None, None),\n",
        "        (\"OTDR length\", 9, None, None),\n",
        "        (\"Attenuation 1310 I/E\", 5, None, None),\n",
        "        (\"Attenuation 1310 O/E\", 6, None, None),\n",
        "        (\"Attenuation 1383 I/E\", 73, None, None),\n",
        "        (\"Attenuation 1383 O/E\", 74, None, None),\n",
        "        (\"Attenuation 1550 I/E\", 7, None, None),\n",
        "        (\"Attenuation 1550 O/E\", 8, None, None),\n",
        "        (\"Attenuation 1625 I/E\", 75, None, None),\n",
        "        (\"Attenuation 1625 O/E\", 76, None, None),\n",
        "        (\"MFD 1310nm I/E\", 12, None, None),\n",
        "        (\"MFD 1310nm O/E\", 13, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"Cutoff 2m I/E\", 14, None, None),\n",
        "        (\"Cutoff 2m O/E\", 15, None, None),\n",
        "        (\"Cutoff 22m\", 24, None, None),\n",
        "        (\"delta 2m-22m\", None, 'delta', None),\n",
        "        (\"Mac value\", None, 'mac', None),\n",
        "        (\"Clad Dia. I/E\", 16, None, None),\n",
        "        (\"Clad Dia. O/E\", 17, None, None),\n",
        "        (\"Clad Ovality I/E\", 18, None, None),\n",
        "        (\"Clad Ovality O/E\", 19, None, None),\n",
        "        (\"Core Ovality I/E\", 20, None, None),\n",
        "        (\"Core Ovality O/E\", 21, None, None),\n",
        "        (\"ECC I/E\", 22, None, None),\n",
        "        (\"ECC O/E\", 23, None, None),\n",
        "        (\"Zero Dispersion Wave.\", 30, None, None),\n",
        "        (\"dispslope at ZDW\", 31, None, None),\n",
        "        (\"Dispersion 1285\", 32, None, None),\n",
        "        (\"Dispersion 1290\", 33, None, None),\n",
        "        (\"Dispersion 1330\", 34, None, None),\n",
        "        (\"Dispersion 1550\", 35, None, None),\n",
        "        (\"\", None, None, None),\n",
        "        (\"PMD\", 37, None, None),\n",
        "        (\"R7.5mm 1t 1550\", 26, 'scale', 0.1),\n",
        "        (\"R7.5mm 1t 1625\", 69, 'scale', 0.1),\n",
        "        (\"R10mm 1t 1550\", 70, 'scale', 0.1),\n",
        "        (\"R10mm 1t 1625\", 71, 'scale', 0.1),\n",
        "        (\"R15mm 10t 1550\", 81, 'scale', 0.5),\n",
        "        (\"R15mm 10t 1625\", 82, 'scale', 0.5),\n",
        "    ]\n",
        "\n",
        "    for subfolder in os.listdir(root_folder):\n",
        "        subfolder_path = os.path.join(root_folder, subfolder)\n",
        "        if not os.path.isdir(subfolder_path):\n",
        "            continue\n",
        "\n",
        "        final_files = [f for f in os.listdir(subfolder_path) if f.endswith(\"final.xlsx\")]\n",
        "        if not final_files:\n",
        "            print(f\"‚ùå '{subfolder}' Ìè¥ÎçîÏóêÎäî final.xlsx ÌååÏùºÏù¥ ÏóÜÏäµÎãàÎã§.\")\n",
        "            continue\n",
        "\n",
        "        final_path = os.path.join(subfolder_path, final_files[0])\n",
        "        try:\n",
        "            df = pd.read_excel(final_path, header=None, engine='openpyxl')\n",
        "            df_result = pd.DataFrame()\n",
        "            n_rows = len(df) - 2  # 3Î≤àÏß∏ Ï§ÑÎ∂ÄÌÑ∞ ÏãúÏûë\n",
        "\n",
        "            for col_idx, (title, src_col, calc_type, factor) in enumerate(column_info):\n",
        "                df_result.loc[0, col_idx] = title  # Ï≤´ Ìñâ Ï†úÎ™©\n",
        "\n",
        "                if calc_type is None:\n",
        "                    if src_col is not None:\n",
        "                        col_values = df.iloc[2:, src_col].tolist()\n",
        "                        for row_idx, val in enumerate(col_values):\n",
        "                            df_result.loc[row_idx + 1, col_idx] = val\n",
        "                elif calc_type == 'delta':\n",
        "                    col_20 = df_result.iloc[1:, 19].astype(float)\n",
        "                    col_21 = df_result.iloc[1:, 20].astype(float)\n",
        "                    df_result.iloc[1:, col_idx] = (col_20 - col_21).round(4)\n",
        "                elif calc_type == 'mac':\n",
        "                    col_12 = pd.to_numeric(df_result.iloc[1:, 11], errors='coerce')\n",
        "                    col_19 = pd.to_numeric(df_result.iloc[1:, 18], errors='coerce')\n",
        "                    df_result.iloc[1:, col_idx] = ((col_12 / col_19) * 1000).round(2)\n",
        "                elif calc_type == 'scale':\n",
        "                    raw_values = df.iloc[2:, src_col]\n",
        "                    scaled_values = []\n",
        "                    for val in raw_values:\n",
        "                        try:\n",
        "                            scaled_values.append(round(float(val) * factor, 4))\n",
        "                        except:\n",
        "                            scaled_values.append(\"\")\n",
        "                    for row_idx, val in enumerate(scaled_values):\n",
        "                        df_result.loc[row_idx + 1, col_idx] = val\n",
        "\n",
        "            save_path = os.path.join(subfolder_path, f\"{subfolder}_final_result_report.xlsx\")\n",
        "            df_result.to_excel(save_path, index=False, header=False)\n",
        "            print(f\"‚úÖ Ï†ÄÏû• ÏôÑÎ£å: {save_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Ïò§Î•ò Î∞úÏÉù ({subfolder}): {e}\")"
      ],
      "metadata": {
        "id": "926vnwNINzRR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**main.py**"
      ],
      "metadata": {
        "id": "2GW53k4VN1bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from preform import run_preform\n",
        "from classification import run_classification\n",
        "from grouping import run_grouping\n",
        "from average import run_average\n",
        "from auto_analyzer import run_auto_analyzer\n",
        "\n",
        "def main():\n",
        "    # 1. Ï≤´ Î≤àÏß∏ ÏûêÎèô ÏûÖÎ†•\n",
        "    print(\"ÏõîÎ≥Ñ Ïñ¥Îñ§ Í∞íÏùÑ Ï∂îÏ∂úÌï† Í≤ÉÏûÖÎãàÍπå?\\n1. rit_no\\n2. resin_type\")\n",
        "    time.sleep(2)\n",
        "    print(\"1Ïù¥ ÏûêÎèôÏúºÎ°ú ÏûÖÎ†•Îê©ÎãàÎã§.\")\n",
        "    result_path_1, summary_1 = run_preform(\"1\")\n",
        "    print(\"\\n[1Î≤à Í≤∞Í≥º]\")\n",
        "    print(\"\\n\".join(summary_1))\n",
        "    print(f\"‚úîÔ∏è preform ÏôÑÎ£å: {result_path_1}\\n\")\n",
        "\n",
        "    # 2. Îëê Î≤àÏß∏ ÏûêÎèô ÏûÖÎ†•\n",
        "    time.sleep(2)\n",
        "    print(\"2Ïù¥ ÏûêÎèôÏúºÎ°ú ÏûÖÎ†•Îê©ÎãàÎã§.\")\n",
        "    result_path_2, summary_2 = run_preform(\"2\")\n",
        "    print(\"\\n[2Î≤à Í≤∞Í≥º]\")\n",
        "    print(\"\\n\".join(summary_2))\n",
        "    print(f\"‚úîÔ∏è preform ÏôÑÎ£å: {result_path_2}\\n\")\n",
        "\n",
        "    # 3. Í¥ÄÏã¨ ÌîÑÎ¶¨Ìèº Ï†ëÎëêÏÇ¨ ÏûÖÎ†•\n",
        "    print(\"\\nÍ¥ÄÏã¨ ÌîÑÎ¶¨Ìèº Ï†ëÎëêÏÇ¨Î•º ÌïòÎÇòÏî© ÏûÖÎ†•ÌïòÏÑ∏Ïöî. (ÎÅùÎÇ¥Î†§Î©¥ 'a' ÏûÖÎ†•)\")\n",
        "    prefixes = []\n",
        "    while True:\n",
        "        pf = input(\"‚ñ∂ ÌîÑÎ¶¨Ìèº ÏûÖÎ†•: \").strip()\n",
        "        if pf.lower() == 'a':\n",
        "            break\n",
        "        if pf:\n",
        "            prefixes.append(pf)\n",
        "    if not prefixes:\n",
        "        print(\"‚ùóÏûÖÎ†•Îêú ÌîÑÎ¶¨ÌèºÏù¥ ÏóÜÏäµÎãàÎã§. ÌîÑÎ°úÍ∑∏Îû®ÏùÑ Ï¢ÖÎ£åÌï©ÎãàÎã§.\")\n",
        "        return\n",
        "\n",
        "    desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
        "\n",
        "    # 4. classification.py Ïã§Ìñâ\n",
        "    print(\"\\n[2/5] classification.py Ïã§ÌñâÏ§ë...\")\n",
        "    classified_files = run_classification(prefixes)\n",
        "    print(f\"‚úîÔ∏è classification ÏôÑÎ£å: {len(classified_files)}Í∞ú ÌååÏùº Î∂ÑÎ•ò\")\n",
        "\n",
        "    # 5. grouping.py Ïã§Ìñâ\n",
        "    print(\"\\n[3/5] grouping.py Ïã§ÌñâÏ§ë...\")\n",
        "    grouped_files = run_grouping(\"grouped_by_prefix\", \"grouped_by_prefix_split\")\n",
        "    print(f\"‚úîÔ∏è grouping ÏôÑÎ£å: {len(grouped_files)}Í∞ú ÌååÏùº ÏÉùÏÑ±\")\n",
        "\n",
        "    # 6. average.py Ïã§Ìñâ\n",
        "    print(\"\\n[4/5] average.py Ïã§ÌñâÏ§ë...\")\n",
        "    average_files = run_average(os.path.join(desktop_path, \"grouped_by_prefix_split\"))\n",
        "    print(f\"‚úîÔ∏è average ÏôÑÎ£å: {len(average_files)}Í∞ú ÏöîÏïΩ ÌååÏùº ÏÉùÏÑ±\")\n",
        "\n",
        "    # 7. auto_analyzer.py Ïã§Ìñâ\n",
        "    print(\"\\n[5/5] auto_analyzer.py Ïã§ÌñâÏ§ë...\")\n",
        "    run_auto_analyzer(os.path.join(desktop_path, \"grouped_by_prefix_split\"))\n",
        "    print(f\"‚úîÔ∏è auto_analyzer ÏôÑÎ£å\")\n",
        "\n",
        "    print(\"\\nüéâ Ï†ÑÏ≤¥ ÏûêÎèôÌôî ÌååÏù¥ÌîÑÎùºÏù∏Ïù¥ Ï¢ÖÎ£åÎêòÏóàÏäµÎãàÎã§.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "cxIs7T4bN4zQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}