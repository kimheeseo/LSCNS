#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í†µí•© ê´‘ì„¬ìœ  ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸ (One-File Edition)
ì‘ì„±ì: ###
ëª©ì : ì‚°ì¬ëœ ìŠ¤í¬ë¦½íŠ¸(resin/zero/group/final/type/analyzer)ë¥¼ í•˜ë‚˜ë¡œ í†µí•©í•˜ì—¬
     ë‹¨ì¼ íŒŒì¼ì—ì„œ ì¼ê´„ ì‹¤í–‰/ë¶€ë¶„ ì‹¤í–‰ì´ ê°€ëŠ¥í•˜ë„ë¡ êµ¬ì„±

Python 3.9+ ê¶Œì¥. ì˜ì¡´ì„±: pandas, openpyxl

ì‚¬ìš© ì˜ˆì‹œ:
  1) ì „ì²´ ì‹¤í–‰:          python integrated_fiber_analyzer.py run-all
  2) ì¼ë¶€ ë‹¨ê³„ë§Œ:        python integrated_fiber_analyzer.py run zero group collect-avg reports collect-total
  3) ì˜µì…˜ í™•ì¸/ë„ì›€ë§:   python integrated_fiber_analyzer.py -h

ì£¼ìš” ì…ë ¥/ì¶œë ¥ ê²½ë¡œ(ê¸°ë³¸ê°’):
  - ab.xlsx                 : ë ˆì§„/ì ‘ë‘ì–´ ë¶„ì„ìš© ì›ë³¸
  - alls.xlsx               : ì „ì²´ ë°ì´í„° ì›ë³¸
  - alls_cleaned.xlsx       : 0 â†’ ë¹ˆì¹¸ ì²˜ë¦¬ëœ íŒŒì¼(ì¤‘ê°„ ì‚°ì¶œ)
  - grouped_by_prefix/      : draw_no ì• 3ê¸€ì ê¸°ì¤€ìœ¼ë¡œ í´ë” êµ¬ì„±
  - grouped_by_col4/        : 3/4ì—´ ê¸°ë°˜ ê·¸ë£¨í•‘ ê²°ê³¼ ë£¨íŠ¸ ë° í›„ì† ì‚°ì¶œë¬¼ ì €ì¥ ìœ„ì¹˜
  - grouped_by_col4/<ì½”ë“œ>/<ì½”ë“œ>.xlsx                        : ì ‘ë‘ì–´ë³„ í‰ê· í–‰ í†µí•© íŒŒì¼
  - grouped_by_col4/<ì½”ë“œ>/<ì½”ë“œ>_final_result_report.xlsx    : ê° í´ë” ë¦¬í¬íŠ¸
  - grouped_by_col4/total_final_result.xlsx                   : ì „ì²´ í†µí•© ë¦¬í¬íŠ¸

ì£¼ì˜:
  - ìœˆë„ìš° ì½˜ì†” UTF-8, í™”ë©´+íŒŒì¼ ë™ì‹œ ë¡œê¹… ì§€ì›
  - ë‹¨ê³„ë³„ ì‹¤íŒ¨ ì‹œ STOP_ON_ERROR ì„¤ì •ì— ë”°ë¼ ì¤‘ë‹¨/ê³„ì†
  - ì—´ ì¸ë±ìŠ¤ëŠ” 0-based

ì¶”ê°€(ìš”ì²­ ë°˜ì˜):
  - group ë‹¨ê³„ì—ì„œ ì—‘ì…€ ì €ì¥ ì „, "3ë²ˆì§¸ ì—´(0-based index 2)" ê°’ì´ ê°™ì€ í–‰ì€
    ì²« ë²ˆì§¸ë§Œ ë‚¨ê¸°ê³  ì œê±°í•œ ë’¤ í‰ê· í–‰ì„ ê³„ì‚°/ì¶”ê°€í•©ë‹ˆë‹¤.

ì‹ ê·œ(ìš”ì²­ ë°˜ì˜):
  - collect-total ì´í›„ "post-analyze" ë‹¨ê³„ ì¶”ê°€
    Â· 23ë²ˆì§¸ ì—´(0-based 22) delta(2m)-22mì˜ ìµœì†Ÿ/ìµœëŒ“ê°’ì„ ì°¾ì•„ ì½˜ì†”ì— ì•Œë¦¬ê³ , í•´ë‹¹ ì…€ë§Œ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œ
    Â· 25/26ë²ˆì§¸ ì—´(0-based 24/25) Clad Dia. ê°’ì´ 124.3 ë¯¸ë§Œ ë˜ëŠ” 125.7 ì´ˆê³¼ë©´ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œ,
      ì½˜ì†”ì— "ì´ìƒê°’ ë°œê²¬" ë° í•´ë‹¹ í–‰ì˜ 2ë²ˆì§¸ ì—´ ê°’ ì¶œë ¥
    Â· ê²°ê³¼ íŒŒì¼: grouped_by_col4/total_final_result_annotated.xlsx
"""

from __future__ import annotations

import argparse
import os
import re
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì˜ì¡´ì„± ì ê²€
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:  # ì§€ì—° ì„í¬íŠ¸ ëŒ€ë¹„, ì¦‰ì‹œ ì‹¤íŒ¨ ì‹œ ì¹œì ˆ ë©”ì‹œì§€
    import pandas as pd
    import numpy as np
except Exception as e:  # pragma: no cover
    print("[ì˜¤ë¥˜] pandas ë˜ëŠ” numpy ì„í¬íŠ¸ ì‹¤íŒ¨.")
    print("       pipë¡œ ì„¤ì¹˜í•´ ì£¼ì„¸ìš”:  pip install pandas openpyxl numpy")
    raise

# openpyxlì€ pandasê°€ ë‚´ë¶€ì—ì„œ ì‚¬ìš©

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¤ì •ê°’
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@dataclass
class Config:
    # ì£¼ìš” íŒŒì¼/í´ë” ê²½ë¡œ
    excel_ab: Path = Path("ab.xlsx")
    excel_alls: Path = Path("alls.xlsx")
    excel_alls_cleaned: Path = Path("alls_cleaned.xlsx")
    out_grouped_by_prefix: Path = Path("grouped_by_prefix")
    out_grouped_by_col4: Path = Path("grouped_by_col4")

    # ì—´ ì¸ë±ìŠ¤(0-based)
    resin_col_idx: int = 4     # ab.xlsxì˜ 5ë²ˆì§¸ ì—´(E)
    drawno_col_idx: int = 0    # ab.xlsxì˜ 1ë²ˆì§¸ ì—´(A)
    col3_idx: int = 2          # alls_cleaned.xlsx ì˜ Cì—´
    col4_idx: int = 3          # alls_cleaned.xlsx ì˜ Dì—´

    # ê·œì¹™/ë™ì‘ í† ê¸€
    use_w_pattern_first: bool = False  # ì ‘ë‘ ì¶”ì¶œ ì‹œ W-íŒ¨í„´ ìš°ì„  ì—¬ë¶€
    filter_second_last_zero: bool = True  # Cì—´ì˜ ë’¤ì—ì„œ 2ë²ˆì§¸ê°€ '0'ì¸ í–‰ë§Œ ì‚¬ìš©
    stop_on_error: bool = True

    # ë¡œê¹…
    log_dir: Path = Path("logs")

    # type.py ë§¤í•‘
    type_map: Dict[str, Dict[str, List[str]]] = field(default_factory=lambda: {
        "LWPF(90)":  {"SEC": ["W00", "W0J"], "Sumitomo": ["20M"]},
        "LWPF(150)": {"SEC": ["L0E"],           "Sumitomo": ["L0M"]},
        "LWPF(180)": {"SEC": ["S0E"],           "Sumitomo": ["S0M"]},
        "A1(90)":    {"SEC": [],                "Sumitomo": ["Z0M"]},
        "A1(150)":   {"SEC": [],                "Sumitomo": ["Z0L"]},
        "A2(90)":    {"SEC": ["AJW", "AJF", "AJB"], "Sumitomo": []},
        "A2(150)":   {"SEC": ["AL"],            "Sumitomo": []},
    })


CFG = Config()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì½˜ì†”/ë¡œê¹… ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class _Tee:
    def __init__(self, *streams):
        self.streams = streams

    def write(self, data):
        for s in self.streams:
            try:
                s.write(data)
                s.flush()
            except Exception:
                pass

    def flush(self):
        for s in self.streams:
            try:
                s.flush()
            except Exception:
                pass

    def isatty(self):
        return any(getattr(s, "isatty", lambda: False)() for s in self.streams)


def setup_utf8_console_and_env() -> Dict[str, str]:
    if os.name == "nt":
        try:
            import ctypes
            ctypes.windll.kernel32.SetConsoleCP(65001)
            ctypes.windll.kernel32.SetConsoleOutputCP(65001)
        except Exception:
            pass
    try:
        sys.stdout.reconfigure(encoding="utf-8", errors="replace")
        sys.stderr.reconfigure(encoding="utf-8", errors="replace")
    except Exception:
        pass
    env = os.environ.copy()
    env["PYTHONIOENCODING"] = "utf-8"
    env["PYTHONUTF8"] = "1"
    return env


class Logger:
    def __init__(self, cfg: Config):
        self.cfg = cfg
        self.cfg.log_dir.mkdir(exist_ok=True)
        self.log_path = self.cfg.log_dir / f"run_{datetime.now():%Y%m%d_%H%M%S}.txt"
        self._log_f = open(self.log_path, "w", encoding="utf-8", newline="")
        sys.stdout = _Tee(sys.__stdout__, self._log_f)
        sys.stderr = _Tee(sys.__stderr__, self._log_f)

    def close(self):
        try:
            self._log_f.close()
        except Exception:
            pass


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³µí†µ ìœ í‹¸ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SAFE_NAME = re.compile(r"^[A-Za-z0-9_\-.]+$")
W_PREFIX_REGEX = re.compile(r"^([A-Z0-9]{3}\d{5}[A-Z]\d{2}W\d{2}[^0-9])")
GENERIC_RIGHTMOST_CHAR_BEFORE_DIGIT = re.compile(r"^(.+[A-Z])(?=\d)")
FILENAME_TO_PREFORM = re.compile(r"^([A-Z0-9]{3}\d{5}).*?([A-Z])$")
ZERO_LIKE = re.compile(r'^[\+\-]?\s*0+(?:[.,]0+)?\s*$')


def normalize_str(x) -> Optional[str]:
    if pd.isna(x):
        return None
    s = str(x).strip()
    return s if s else None


def second_last_is_zero(val) -> bool:
    if pd.isna(val):
        return False
    s = str(val).strip()
    return len(s) >= 2 and s[-2] == "0"


def safe_filename(name: str) -> str:
    s = str(name).strip() or "EMPTY"
    return re.sub(r"[^A-Za-z0-9._-]+", "_", s)


def make_avg_row(df: pd.DataFrame) -> Dict[str, object]:
    avg = {}
    for col in df.columns:
        s_num = pd.to_numeric(df[col], errors="coerce")
        avg[col] = s_num.mean() if s_num.notna().any() else ""
    return avg


def extract_prefix_generic(s: str) -> str:
    if s is None:
        return ""
    t = str(s).strip().upper()
    if not t:
        return ""
    m = GENERIC_RIGHTMOST_CHAR_BEFORE_DIGIT.search(t)
    return m.group(1) if m else t


def extract_prefix_wpattern(s: str) -> str:
    if s is None:
        return ""
    t = str(s).strip().upper()
    m = W_PREFIX_REGEX.match(t)
    return m.group(1) if m else ""


def extract_group_prefix(s: str, use_w_first: bool) -> str:
    if use_w_first:
        p = extract_prefix_wpattern(s)
        return p if p else extract_prefix_generic(s)
    else:
        p = extract_prefix_generic(s)
        return p if p else extract_prefix_wpattern(s)


def is_empty(val) -> bool:
    if val is None:
        return True
    try:
        if pd.isna(val):
            return True
    except Exception:
        pass
    return str(val).strip() == ""


def candidate_files(prefix_dir: Path) -> List[Path]:
    out_file = prefix_dir / f"{prefix_dir.name}.xlsx"
    return sorted(
        p for p in prefix_dir.glob("*.xlsx")
        if p.name.lower() != out_file.name.lower() and not p.name.startswith("~$")
    )


def preform_from_filename(path: Path, fallback: Optional[str] = None) -> Optional[str]:
    stem = path.stem.upper()
    m = FILENAME_TO_PREFORM.match(stem)
    if m:
        base8, last_letter = m.group(1), m.group(2)
        return f"{base8}{last_letter}"
    return fallback


def _normalize_as_text(s: pd.Series) -> pd.Series:
    out = s.astype("string").fillna("")
    out = out.str.replace(r"\.0$", "", regex=True)
    return out.astype("object")


def _is_temp_or_hidden(p: Path) -> bool:
    name = p.name
    return name.startswith("~$") or name.startswith(".") or name.endswith(".tmp")


def pick_input_file(subfolder: Path) -> Optional[Path]:
    c1 = subfolder / f"{subfolder.name}.xlsx"
    c2 = subfolder / "final.xlsx"
    if c1.exists():
        return c1
    if c2.exists():
        return c2
    return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë‹¨ê³„ êµ¬í˜„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def step_resin_analyze_and_group_ab(cfg: Config) -> int:
    print("[resin] ab.xlsx ë ˆì§„/ì ‘ë‘ì–´ ë¶„ì„ ë° í´ë” êµ¬ì„±")
    if not cfg.excel_ab.exists():
        print(f"[resin][ì˜¤ë¥˜] ì—‘ì…€ íŒŒì¼ ì—†ìŒ: {cfg.excel_ab.resolve()}")
        return 1

    df = pd.read_excel(cfg.excel_ab, engine="openpyxl")

    # (1) ë ˆì§„ ì§‘ê³„
    if cfg.resin_col_idx >= df.shape[1]:
        print(f"[resin][ì˜¤ë¥˜] 5ë²ˆì§¸ ì—´(ì¸ë±ìŠ¤ {cfg.resin_col_idx}) ì—†ìŒ. ì‹¤ì œ ì—´ ìˆ˜: {df.shape[1]}")
        return 1

    resin_series = (
        df.iloc[:, cfg.resin_col_idx].map(normalize_str).dropna().map(lambda s: s.upper())
    )

    if len(resin_series) == 0:
        print("[resin] ìœ íš¨í•œ ë ˆì§„ íƒ€ì…ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        resin_counts = resin_series.value_counts().sort_index()
        types_str = ",".join(resin_counts.index)
        print(f"[resin] ë ˆì§„ íƒ€ì…: {types_str}")
        for t, c in resin_counts.items():
            print(f"[resin] {t}: {c}ê°œ")

    # (2) draw_no ì• 3ê¸€ì ê¸°ì¤€ í´ë” êµ¬ì„±
    if cfg.drawno_col_idx >= df.shape[1]:
        print(f"[resin][ì˜¤ë¥˜] 1ë²ˆì§¸ ì—´(ì¸ë±ìŠ¤ {cfg.drawno_col_idx}) ì—†ìŒ. ì‹¤ì œ ì—´ ìˆ˜: {df.shape[1]}")
        return 1

    draw_series = df.iloc[:, cfg.drawno_col_idx].map(normalize_str).dropna()

    prefix_map: Dict[str, set] = {}
    for val in draw_series:
        if len(val) < 3:
            continue
        if not SAFE_NAME.match(val):
            continue
        prefix = val[:3]
        if not SAFE_NAME.match(prefix):
            continue
        prefix_map.setdefault(prefix, set()).add(val)

    cfg.out_grouped_by_prefix.mkdir(parents=True, exist_ok=True)
    for prefix, fullset in prefix_map.items():
        prefix_dir = cfg.out_grouped_by_prefix / prefix
        prefix_dir.mkdir(exist_ok=True)
        for full in sorted(fullset):
            (prefix_dir / full).mkdir(exist_ok=True)

    if prefix_map:
        prefix_list = ",".join(sorted(prefix_map.keys()))
        print(f"[resin] ì¡°íšŒëœ ì ‘ë‘ì–´: {prefix_list}")
        for prefix in sorted(prefix_map.keys()):
            cnt = len(prefix_map[prefix])
            print(f"[resin] {prefix}: draw_no {cnt}ê°œ")
    else:
        print("[resin] ì ‘ë‘ì–´ ê¸°ë°˜ í´ë” ìƒì„± ëŒ€ìƒ ì—†ìŒ")

    # (ì„ íƒ) ìš”ì•½ CSV ì €ì¥
    try:
        if len(resin_series) > 0:
            resin_counts.to_frame("count").to_csv(cfg.excel_ab.with_name("resin_type_counts.csv"))
        if prefix_map:
            import csv
            out_csv = cfg.excel_ab.with_name("prefix_drawno_counts.csv")
            with out_csv.open("w", newline="", encoding="utf-8") as f:
                w = csv.writer(f)
                w.writerow(["prefix", "draw_no_count"])
                for p in sorted(prefix_map.keys()):
                    w.writerow([p, len(prefix_map[p])])
    except Exception as e:
        print(f"[resin](ê²½ê³ ) ìš”ì•½ CSV ì €ì¥ ì‹¤íŒ¨: {e}")

    return 0


def step_zero_to_blank_all(cfg: Config) -> int:
    print("[zero] 0 â†’ ë¹ˆì¹¸(None) ë³€í™˜")
    if not cfg.excel_alls.exists():
        print(f"[zero][ì˜¤ë¥˜] ì—‘ì…€ íŒŒì¼ ì—†ìŒ: {cfg.excel_alls.resolve()}")
        return 1

    df = pd.read_excel(cfg.excel_alls, engine="openpyxl")

    # ìˆ«ìí˜• 0 â†’ None (bool ì œì™¸)
    num_cols = df.select_dtypes(include=[np.number]).columns
    bool_cols = df.select_dtypes(include=["bool"]).columns
    num_cols = [c for c in num_cols if c not in bool_cols]

    for c in num_cols:
        df[c] = df[c].mask(df[c] == 0, other=None)

    # ë¹„ìˆ«ìí˜•ì—ì„œ '0' ë³€í˜•ë“¤ â†’ None
    obj_cols = df.columns.difference(num_cols).tolist()
    for c in obj_cols:
        s = df[c]
        s_str = s.astype(str)
        mask = s_str.str.match(ZERO_LIKE, na=False)
        num_eq_zero = pd.to_numeric(s_str.str.replace(",", ".", regex=False), errors="coerce").eq(0)
        final_mask = (mask | num_eq_zero) & s.notna()
        df.loc[final_mask, c] = None

    df.to_excel(cfg.excel_alls_cleaned, index=False, engine="openpyxl")
    print(f"[zero] ì™„ë£Œ â†’ {cfg.excel_alls_cleaned.resolve()}")
    return 0


def step_group_by_col4_with_prefix_and_avg(cfg: Config) -> int:
    print("[group] 3/4ì—´ ê¸°ë°˜ ê·¸ë£¹ ì €ì¥ + í‰ê· í–‰ ì¶”ê°€ (ì¤‘ë³µ ì œê±° í›„)")
    if not cfg.excel_alls_cleaned.exists():
        print(f"[group][ì˜¤ë¥˜] íŒŒì¼ ì—†ìŒ: {cfg.excel_alls_cleaned.resolve()}")
        return 1

    df = pd.read_excel(cfg.excel_alls_cleaned, engine="openpyxl")

    need_max = max(cfg.col3_idx, cfg.col4_idx)
    if df.shape[1] <= need_max:
        print(f"[group][ì˜¤ë¥˜] ì—´ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. í˜„ì¬ {df.shape[1]}ì—´, í•„ìš” ìµœì†Œ {need_max+1}")
        return 1

    col3 = df.columns[cfg.col3_idx]
    col4 = df.columns[cfg.col4_idx]

    # (A) Cì—´ í•„í„° (ì˜µì…˜)
    filtered = df.copy()
    if cfg.filter_second_last_zero:
        mask = filtered[col3].map(second_last_is_zero)
        filtered = filtered[mask].copy()

    # (B) Dì—´ ê³µë°± ì œê±°
    filtered = filtered[filtered[col4].notna() & (filtered[col4].astype(str).str.strip() != "")]
    if filtered.empty:
        print("[group] í•„í„° í›„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    # (C) ê·¸ë£¹ í‚¤ ì¶”ì¶œ
    filtered["_group_key_"] = filtered[col3].apply(lambda s: extract_group_prefix(s, cfg.use_w_pattern_first))
    filtered = filtered[filtered["_group_key_"].astype(str).str.strip() != ""]
    if filtered.empty:
        print("[group] ìœ íš¨í•œ ê·¸ë£¹ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    cfg.out_grouped_by_col4.mkdir(parents=True, exist_ok=True)

    from collections import defaultdict
    prefix_counts: Dict[str, int] = defaultdict(int)

    for key, g in filtered.groupby("_group_key_", dropna=False):
        key_str = str(key).strip()
        if not key_str:
            continue

        prefix3 = key_str[:3] if len(key_str) >= 3 else "UNK"
        dest_dir = cfg.out_grouped_by_col4 / prefix3
        dest_dir.mkdir(parents=True, exist_ok=True)

        # === ì €ì¥ ëŒ€ìƒ í…Œì´ë¸” êµ¬ì„± ===
        g_out = g.drop(columns=["_group_key_"]).copy()

        # ğŸ”¹ (ì¶”ê°€) í‰ê·  ê³„ì‚° ì „ì— "3ë²ˆì§¸ ì—´(ì¸ë±ìŠ¤ 2)" ê¸°ì¤€ ì¤‘ë³µ ì œê±°
        if g_out.shape[1] >= 3:
            dedup_col = g_out.columns[2]  # 0-based: 2 -> 3ë²ˆì§¸ ì—´
            before_n = len(g_out)
            g_out["_dedup_key_"] = g_out[dedup_col].map(normalize_str)
            g_out = (
                g_out
                .drop_duplicates(subset=["_dedup_key_"], keep="first")
                .drop(columns=["_dedup_key_"])
                .reset_index(drop=True)
            )
            removed = before_n - len(g_out)
            if removed > 0:
                print(f"[group][ì¤‘ë³µì œê±°] {key_str}: 3ë²ˆì§¸ ì—´ '{dedup_col}' ê¸°ì¤€ {removed}í–‰ ì œê±°")
        else:
            print(f"[group][ì •ë³´] {key_str}: ì—´ ìˆ˜ê°€ 3 ë¯¸ë§Œì´ë¼ ì¤‘ë³µ ì œê±° ìŠ¤í‚µ")

        # ğŸ”¹ í‰ê· í–‰ ê³„ì‚° ë° ë¶€ì°©
        avg_row = make_avg_row(g_out)
        g_out = pd.concat([g_out, pd.DataFrame([avg_row])], ignore_index=True)

        out_path = dest_dir / f"{safe_filename(key_str)}.xlsx"
        try:
            g_out.to_excel(out_path, index=False, engine="openpyxl")
        except Exception as e:
            print(f"[group][ì˜¤ë¥˜] ì €ì¥ ì‹¤íŒ¨: {out_path.name} â†’ {e}")
            continue

        prefix_counts[prefix3] += 1

    for pfx in sorted(prefix_counts.keys()):
        print(f"[group] {pfx}: {prefix_counts[pfx]}ê°œ íŒŒì¼ ì €ì¥")

    return 0


def step_collect_all_prefix_averages(cfg: Config) -> int:
    print("[collect-avg] ì ‘ë‘ì–´ë³„ í‰ê· í–‰ ì·¨í•©")
    base = cfg.out_grouped_by_col4
    if not base.exists():
        print(f"[collect-avg][ì˜¤ë¥˜] í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {base.resolve()}")
        return 1

    prefix_dirs = sorted(p for p in base.iterdir() if p.is_dir() and not p.name.startswith("~$"))
    if not prefix_dirs:
        print("[collect-avg] ì²˜ë¦¬í•  ì ‘ë‘ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    for pdir in prefix_dirs:
        out_file = pdir / f"{pdir.name}.xlsx"
        excel_files = candidate_files(pdir)
        if not excel_files:
            print(f"[collect-avg][INFO] {pdir.name}: ìˆ˜ì§‘í•  íŒŒì¼ ì—†ìŒ")
            continue

        last_rows: List[pd.DataFrame] = []
        for path in excel_files:
            try:
                df = pd.read_excel(path, engine="openpyxl")
            except Exception as e:
                print(f"[collect-avg][ê²½ê³ ] ì½ê¸° ì‹¤íŒ¨: {path.name} â†’ {e}")
                continue
            if df.empty:
                print(f"[collect-avg][ê±´ë„ˆëœ€] ë¹ˆ íŒŒì¼: {path.name}")
                continue

            last_idx = len(df) - 1
            if df.shape[1] > cfg.col4_idx and last_idx >= 1:
                if is_empty(df.iat[last_idx, cfg.col4_idx]):
                    df.iat[last_idx, cfg.col4_idx] = df.iat[last_idx - 1, cfg.col4_idx]

            try:
                current_val = df.iat[last_idx, cfg.col4_idx] if df.shape[1] > cfg.col4_idx else None
                new_preform = preform_from_filename(path, fallback=str(current_val) if current_val is not None else None)
                if new_preform is not None and df.shape[1] > cfg.col4_idx:
                    df.iloc[:, cfg.col4_idx] = df.iloc[:, cfg.col4_idx].astype("object")
                    df.iat[last_idx, cfg.col4_idx] = new_preform
            except Exception as e:
                print(f"[collect-avg][ê²½ê³ ] {path.name}: preform ë®ì–´ì“°ê¸° ì˜¤ë¥˜ â†’ {e}")

            last_rows.append(df.iloc[[last_idx]].copy())

        if not last_rows:
            print(f"[collect-avg][INFO] {pdir.name}: í‰ê·  í–‰ ì—†ìŒ")
            continue

        result = pd.concat(last_rows, ignore_index=True, sort=False)
        try:
            result.to_excel(out_file, index=False, engine="openpyxl")
            print(f"[collect-avg][ì €ì¥] {out_file.resolve()} (ì´ {len(result)}í–‰)")
        except Exception as e:
            print(f"[collect-avg][ì˜¤ë¥˜] {pdir.name} ì €ì¥ ì‹¤íŒ¨ â†’ {e}")

    return 0


def step_copy_col4_to_col2_in_prefix_books(cfg: Config) -> int:
    print("[copy-42] ì ‘ë‘ì–´ í†µí•©íŒŒì¼ì—ì„œ 4ë²ˆì§¸ ì—´ â†’ 2ë²ˆì§¸ ì—´(ë¬¸ìì—´) ë³µì‚¬")
    root = cfg.out_grouped_by_col4
    if not root.exists():
        print(f"[copy-42][ì˜¤ë¥˜] í´ë” ì—†ìŒ: {root.resolve()}")
        return 1

    SECOND_COL_IDX = 1
    FOURTH_COL_IDX = 3

    prefix_dirs = sorted(p for p in root.iterdir() if p.is_dir() and not _is_temp_or_hidden(p))
    if not prefix_dirs:
        print("[copy-42][ì •ë³´] ì²˜ë¦¬í•  ì ‘ë‘ì–´ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    for pdir in prefix_dirs:
        target_xlsx = pdir / f"{pdir.name}.xlsx"
        if not target_xlsx.exists():
            print(f"[copy-42][ê±´ë„ˆëœ€] ëŒ€ìƒ íŒŒì¼ ì—†ìŒ: {target_xlsx}")
            continue

        try:
            df = pd.read_excel(target_xlsx, engine="openpyxl")
        except Exception as e:
            print(f"[copy-42][ì˜¤ë¥˜] ì½ê¸° ì‹¤íŒ¨: {target_xlsx.name} â†’ {e}")
            continue

        if df.empty:
            print(f"[copy-42][ê±´ë„ˆëœ€] ë¹ˆ íŒŒì¼: {target_xlsx.name}")
            continue

        needed = max(SECOND_COL_IDX, FOURTH_COL_IDX) + 1
        if df.shape[1] < needed:
            print(f"[copy-42][ê²½ê³ ] {target_xlsx.name}: ì—´ ìˆ˜ ë¶€ì¡±({df.shape[1]}ì—´) â†’ ë³µì‚¬ ìŠ¤í‚µ")
            continue

        dst_col = df.columns[SECOND_COL_IDX]
        src_col = df.columns[FOURTH_COL_IDX]

        df[dst_col] = _normalize_as_text(df[dst_col])
        src_as_text = _normalize_as_text(df[src_col])
        df[dst_col] = src_as_text

        try:
            df.to_excel(target_xlsx, index=False, engine="openpyxl")
            print(f"[copy-42][ì™„ë£Œ] {target_xlsx}")
        except Exception as e:
            print(f"[copy-42][ì˜¤ë¥˜] ì €ì¥ ì‹¤íŒ¨: {target_xlsx.name} â†’ {e}")

    return 0


def step_summarize_types(cfg: Config) -> int:
    print("[types] íƒ€ì…/ì œì¡°ì‚¬ ë³´ìœ  ìš”ì•½")
    base = cfg.out_grouped_by_col4
    if not base.exists():
        print(f"[types][ì˜¤ë¥˜] í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {base.resolve()}")
        return 1

    folder_names = set()
    for p in base.iterdir():
        if p.is_dir():
            name = p.name.strip()
            if name and not name.startswith("~$") and not name.startswith("."):
                folder_names.add(name.upper())

    print("[types] í˜„ì¬ ë³´ìœ  í´ë” ì½”ë“œ:", ", ".join(sorted(folder_names)) if folder_names else "(ì—†ìŒ)")

    defined_upper = set()
    for vendors in cfg.type_map.values():
        for codes in vendors.values():
            defined_upper.update(c.upper() for c in codes)

    matched_present_upper = set()
    any_printed = False

    for type_name, vendors in cfg.type_map.items():
        vendor_parts = []
        for vendor, codes in vendors.items():
            if not codes:
                continue
            present_codes = [c for c in codes if c.upper() in folder_names]
            if present_codes:
                vendor_parts.append(f"{vendor}=" + ", ".join(present_codes))
                matched_present_upper.update(c.upper() for c in present_codes)
        if vendor_parts:
            any_printed = True
            print(f"[types] íƒ€ì… {type_name}: " + " / ".join(vendor_parts) + " ë³´ìœ ")

    others = sorted(folder_names - defined_upper)
    if others:
        print("[types] ê¸°íƒ€:", ", ".join(others))
    if not any_printed and not others:
        print("[types] (ì¼ì¹˜í•˜ëŠ” íƒ€ì… ì½”ë“œê°€ ì•„ì§ ë³´ìœ ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.)")

    return 0


# data_analyzer: ì—´ ë§µ ì •ì˜
COLUMN_INFO: List[Tuple[str, Optional[int], Optional[str], Optional[float]]] = [
    ("spoolno2", 1, None, None),
    ("OTDR length", 9, None, None),
    ("Attenuation 1310 I/E", 5, None, None),
    ("Attenuation 1310 O/E", 6, None, None),
    ("Attenuation 1383 I/E", 73, None, None),
    ("Attenuation 1383 O/E", 74, None, None),
    ("Attenuation 1550 I/E", 7, None, None),
    ("Attenuation 1550 O/E", 8, None, None),
    ("Attenuation 1625 I/E", 75, None, None),
    ("Attenuation 1625 O/E", 76, None, None),
    ("MFD 1310nm I/E", 12, None, None),
    ("MFD 1310nm O/E", 13, None, None),
    ("", None, None, None),
    ("", None, None, None),
    ("", None, None, None),
    ("", None, None, None),
    ("", None, None, None),
    ("", None, None, None),
    ("Cutoff 2m I/E", 14, None, None),
    ("Cutoff 2m O/E", 15, None, None),
    ("Cutoff 22m", 24, None, None),
    ("delta 2m-22m", None, "delta", None),
    ("Mac value", None, "mac", None),
    ("Clad Dia. I/E", 16, None, None),
    ("Clad Dia. O/E", 17, None, None),
    ("Clad Ovality I/E", 18, None, None),
    ("Clad Ovality O/E", 19, None, None),
    ("Core Ovality I/E", 20, None, None),
    ("Core Ovality O/E", 21, None, None),
    ("ECC I/E", 22, None, None),
    ("ECC O/E", 23, None, None),
    ("Zero Dispersion Wave.", 30, None, None),
    ("dispslope at ZDW", 31, None, None),
    ("Dispersion 1285", 32, None, None),
    ("Dispersion 1290", 33, None, None),
    ("Dispersion 1330", 34, None, None),
    ("Dispersion 1550", 35, None, None),
    ("", None, None, None),
    ("PMD", 37, None, None),
    ("R7.5mm 1t 1550", 26, "scale", 0.1),
    ("R7.5mm 1t 1625", 69, "scale", 0.1),
    ("R10mm 1t 1550", 70, "scale", 0.1),
    ("R10mm 1t 1625", 71, "scale", 0.1),
    ("R15mm 10t 1550", 81, "scale", 0.5),
    ("R15mm 10t 1625", 82, "scale", 0.5),
]


def _safe_series(df: pd.DataFrame, col: Optional[int]) -> pd.Series:
    if col is None or col >= df.shape[1]:
        return pd.Series([], dtype="float64")
    return df.iloc[1:, col]


def build_folder_report(subfolder: Path) -> Optional[Path]:
    src = pick_input_file(subfolder)
    if src is None:
        print(f"[report]âŒ ì…ë ¥ ì—†ìŒ: {subfolder.name} (<í´ë”ëª…>.xlsx / final.xlsx)")
        return None

    try:
        df = pd.read_excel(src, header=None, engine="openpyxl")
    except Exception as e:
        print(f"[report]âš ï¸ ì½ê¸° ì˜¤ë¥˜({subfolder.name}): {e}")
        return None

    out = pd.DataFrame()
    for out_idx, (title, src_col, calc, factor) in enumerate(COLUMN_INFO):
        out.loc[0, out_idx] = title
        if calc is None:
            if src_col is None:
                continue
            series = _safe_series(df, src_col)
            for r, v in enumerate(series.tolist()):
                out.loc[r + 1, out_idx] = v
        elif calc == "delta":
            col_20 = pd.to_numeric(out.iloc[1:, 19], errors="coerce")
            col_21 = pd.to_numeric(out.iloc[1:, 20], errors="coerce")
            delta = (col_20 - col_21).round(4)
            for r, v in enumerate(delta.tolist(), start=1):
                out.loc[r, out_idx] = "" if pd.isna(v) else v
        elif calc == "mac":
            mfd_oe = pd.to_numeric(out.iloc[1:, 11], errors="coerce")
            cut_ie = pd.to_numeric(out.iloc[1:, 18], errors="coerce")
            mac = (mfd_oe / cut_ie * 1000).round(2)
            for r, v in enumerate(mac.tolist(), start=1):
                out.loc[r, out_idx] = "" if pd.isna(v) else v
        elif calc == "scale":
            series = _safe_series(df, src_col)
            scaled = (pd.to_numeric(series, errors="coerce") * (factor or 1.0)).round(4)
            for r, v in enumerate(scaled.tolist()):
                out.loc[r + 1, out_idx] = "" if pd.isna(v) else v

    dst = subfolder / f"{subfolder.name}_final_result_report.xlsx"
    try:
        out.to_excel(dst, index=False, header=False, engine="openpyxl")
        print(f"[report]âœ… ì €ì¥: {dst}")
        return dst
    except Exception as e:
        print(f"[report]âš ï¸ ì €ì¥ ì˜¤ë¥˜({subfolder.name}): {e}")
        return None


def step_build_reports(cfg: Config) -> int:
    print("[reports] í•˜ìœ„ í´ë”ë³„ *_final_result_report.xlsx ìƒì„±")
    root = cfg.out_grouped_by_col4
    if not root.exists():
        print(f"[reports][ì˜¤ë¥˜] í´ë” ì—†ìŒ: {root.resolve()}")
        return 1

    subfolders = [p for p in root.iterdir() if p.is_dir() and not p.name.startswith(("~$", "."))]
    if not subfolders:
        print("[reports] ì²˜ë¦¬í•  í•˜ìœ„ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 0

    for sub in sorted(subfolders, key=lambda x: x.name):
        build_folder_report(sub)

    return 0


def collect_to_root(root: Path, total_filename: str = "total_final_result.xlsx") -> Optional[Path]:
    report_paths = sorted(root.glob("*/*_final_result_report.xlsx"))
    if not report_paths:
        print("[collect-total]âš ï¸ í†µí•©í•  ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    merged_list: List[pd.DataFrame] = []
    for p in report_paths:
        try:
            raw = pd.read_excel(p, header=None, engine="openpyxl")
            if raw.empty:
                continue
            headers = raw.iloc[0].tolist()
            data = raw.iloc[1:].reset_index(drop=True)
            data.columns = headers
            data.insert(0, "GROUP", p.parent.name)
            merged_list.append(data)
        except Exception as e:
            print(f"[collect-total]âš ï¸ í†µí•© ì¤‘ ì½ê¸° ì˜¤ë¥˜: {p} â†’ {e}")

    if not merged_list:
        print("[collect-total]âš ï¸ ìœ íš¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    total_df = pd.concat(merged_list, ignore_index=True, sort=False)
    total_path = root / total_filename
    try:
        total_df.to_excel(total_path, index=False, engine="openpyxl")
        print(f"[collect-total]ğŸ“¦ ì €ì¥: {total_path}")
        print("[collect-total] í†µí•©ëª¨ë“œ ì—‘ì…€íŒŒì¼ ì‘ì„±ì™„ë£Œ")
        return total_path
    except Exception as e:
        print(f"[collect-total]âš ï¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None


def step_collect_total(cfg: Config) -> int:
    print("[collect-total] ì „ì²´ í†µí•© íŒŒì¼ ìƒì„±")
    root = cfg.out_grouped_by_col4
    if not root.exists():
        print(f"[collect-total][ì˜¤ë¥˜] í´ë” ì—†ìŒ: {root.resolve()}")
        return 1
    collect_to_root(root, "total_final_result.xlsx")
    return 0


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â˜… ì‹ ê·œ ë‹¨ê³„: total_final_result í›„ ì¶”ê°€ ë¶„ì„/ê°•ì¡° í‘œì‹œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def step_post_analyze_and_highlight(cfg: Config) -> int:
    """
    total_final_result.xlsx ìƒì„± í›„ ì¶”ê°€ ë¶„ì„/ê°•ì¡° í‘œì‹œ:
      1) delta(2m)-22m ê²€ì‚¬ ìˆ˜í–‰
         - 23ë²ˆì§¸ ì—´(0-based index=22)ì„ ìˆ«ìë¡œ ë³€í™˜
         - ìµœëŒ“ê°’/ìµœì†Ÿê°’ì„ ì°¾ê³ , í•´ë‹¹ ì…€ë§Œ ë¹¨ê°„ìƒ‰ í‘œì‹œ
         - ê° ê°’ì— ëŒ€ì‘í•˜ëŠ” 2ë²ˆì§¸ ì—´(0-based index=1)ì˜ ê°’ì„ í•¨ê»˜ ì½˜ì†”ì— ì¶œë ¥
      2) cladding dia ê²€ì‚¬ ìˆ˜í–‰
         - 25, 26ë²ˆì§¸ ì—´(0-based index=24, 25)ì„ ìˆ«ìë¡œ ë³€í™˜
         - 124.3 ë¯¸ë§Œ, 125.7 ì´ˆê³¼ì¸ ê°’ë§Œ ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œ
         - ì´ìƒê°’ ë°œê²¬ ì‹œ "ì´ìƒê°’ ë°œê²¬" ë° í•´ë‹¹ í–‰ì˜ 2ë²ˆì§¸ ì—´ ê°’ ì¶œë ¥
      3) ê²°ê³¼ëŠ” grouped_by_col4/total_final_result_annotated.xlsx ë¡œ ì €ì¥
    """
    root = cfg.out_grouped_by_col4
    total_xlsx = root / "total_final_result.xlsx"
    if not total_xlsx.exists():
        print("[post-analyze][ì˜¤ë¥˜] í†µí•© íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤:", total_xlsx.resolve())
        return 1

    try:
        df = pd.read_excel(total_xlsx, engine="openpyxl")
    except Exception as e:
        print(f"[post-analyze][ì˜¤ë¥˜] í†µí•© íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return 1

    work = df.copy()

    # ì—´ ì¸ë±ìŠ¤(0-based)
    COL_SECOND = 1          # (n,1) = 2ë²ˆì§¸ ì—´
    COL_DELTA = 22          # 23ë²ˆì§¸ ì—´: delta(2m)-22m
    COL_CLAD_IE = 24        # 25ë²ˆì§¸ ì—´: Clad Dia. I/E
    COL_CLAD_OE = 25        # 26ë²ˆì§¸ ì—´: Clad Dia. O/E

    max_needed = max(COL_SECOND, COL_DELTA, COL_CLAD_IE, COL_CLAD_OE)
    if work.shape[1] <= max_needed:
        print(f"[post-analyze][ì˜¤ë¥˜] ì—´ ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (í˜„ì¬ {work.shape[1]}ì—´, í•„ìš” {max_needed+1}ì—´)")
        return 1

    # ìˆ«ì ë³€í™˜
    s_delta = pd.to_numeric(work.iloc[:, COL_DELTA], errors="coerce")
    s_clad_ie = pd.to_numeric(work.iloc[:, COL_CLAD_IE], errors="coerce")
    s_clad_oe = pd.to_numeric(work.iloc[:, COL_CLAD_OE], errors="coerce")

    # â”€â”€ ì½˜ì†” ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    print("1. delta(2m)-22m ê²€ì‚¬ ìˆ˜í–‰")

    valid_delta = s_delta.dropna()
    min_idx_list: List[int] = []
    max_idx_list: List[int] = []
    if valid_delta.empty:
        print("[post-analyze] delta(2m)-22m ìœ íš¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        min_val = valid_delta.min()
        max_val = valid_delta.max()
        min_idx_list = s_delta.index[s_delta == min_val].tolist()
        max_idx_list = s_delta.index[s_delta == max_val].tolist()

        print("delta(2m)-22mì˜ ìµœëŒ“ê°’, ìµœì†Ÿê°’ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.")
        for ridx in min_idx_list:
            sec_val = work.iat[ridx, COL_SECOND]
            print(f"  Â· ìµœì†Ÿê°’: {min_val}  |  2ë²ˆì§¸ ì—´ ê°’: {sec_val}")
        for ridx in max_idx_list:
            sec_val = work.iat[ridx, COL_SECOND]
            print(f"  Â· ìµœëŒ“ê°’: {max_val}  |  2ë²ˆì§¸ ì—´ ê°’: {sec_val}")

    print()
    print("2. cladding dia ê²€ì‚¬ ìˆ˜í–‰")
    LOW, HIGH = 124.3, 125.7

    ie_out_mask = (s_clad_ie < LOW) | (s_clad_ie > HIGH)
    oe_out_mask = (s_clad_oe < LOW) | (s_clad_oe > HIGH)

    any_abnormal = False
    for ridx in ie_out_mask[ie_out_mask].index.tolist():
        any_abnormal = True
        sec_val = work.iat[ridx, COL_SECOND]
        val = s_clad_ie.iat[ridx]
        print(f"ì´ìƒê°’ ë°œê²¬: Clad Dia. I/E = {val} (í–‰ {ridx})  |  2ë²ˆì§¸ ì—´ ê°’: {sec_val}")
    for ridx in oe_out_mask[oe_out_mask].index.tolist():
        any_abnormal = True
        sec_val = work.iat[ridx, COL_SECOND]
        val = s_clad_oe.iat[ridx]
        print(f"ì´ìƒê°’ ë°œê²¬: Clad Dia. O/E = {val} (í–‰ {ridx})  |  2ë²ˆì§¸ ì—´ ê°’: {sec_val}")

    if not any_abnormal:
        print("ì´ìƒê°’ ì—†ìŒ")

    # â”€â”€ ìŠ¤íƒ€ì¼ ì ìš© ì¤€ë¹„ (ë¹¨ê°„ ê¸€ììƒ‰) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    style_df = pd.DataFrame("", index=work.index, columns=work.columns)

    for ridx in min_idx_list:
        style_df.iat[ridx, COL_DELTA] = "color: red;"
    for ridx in max_idx_list:
        style_df.iat[ridx, COL_DELTA] = "color: red;"

    for ridx in ie_out_mask[ie_out_mask].index.tolist():
        style_df.iat[ridx, COL_CLAD_IE] = "color: red;"
    for ridx in oe_out_mask[oe_out_mask].index.tolist():
        style_df.iat[ridx, COL_CLAD_OE] = "color: red;"

    annotated_path = root / "total_final_result_annotated.xlsx"
    try:
        styler = work.style.apply(lambda _: style_df, axis=None)
        styler.to_excel(annotated_path, index=False, engine="openpyxl")
        print(f"[post-analyze] ìŠ¤íƒ€ì¼ ì ìš© íŒŒì¼ ì €ì¥: {annotated_path.name}")
    except Exception as e:
        print(f"[post-analyze][ê²½ê³ ] ìŠ¤íƒ€ì¼ ì ìš© ì €ì¥ ì‹¤íŒ¨: {e}")
        try:
            work.to_excel(annotated_path, index=False, engine="openpyxl")
            print(f"[post-analyze] ë°ì´í„°ë§Œ ì €ì¥ ì™„ë£Œ(ìŠ¤íƒ€ì¼ ë¯¸í¬í•¨): {annotated_path.name}")
        except Exception as e2:
            print(f"[post-analyze][ì˜¤ë¥˜] ë°ì´í„° ì €ì¥ë„ ì‹¤íŒ¨: {e2}")
            return 1

    return 0


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤í–‰ ì—”ì§„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

STEPS: Dict[str, Tuple[str, callable]] = {
    "resin":        ("ë ˆì§„/ì ‘ë‘ì–´ ë¶„ì„ ë° í´ë” êµ¬ì„± (ab.xlsx)", step_resin_analyze_and_group_ab),
    "zero":         ("0 â†’ ë¹ˆì¹¸ ì •ë¦¬ (alls.xlsx â†’ alls_cleaned.xlsx)", step_zero_to_blank_all),
    "group":        ("3/4ì—´ ê¸°ë°˜ ê·¸ë£¹ ì €ì¥ + í‰ê· í–‰ ì¶”ê°€", step_group_by_col4_with_prefix_and_avg),
    "collect-avg":  ("ì ‘ë‘ì–´ë³„ í‰ê· í–‰ í†µí•© íŒŒì¼ ìƒì„± (<ì½”ë“œ>.xlsx)", step_collect_all_prefix_averages),
    "copy-42":      ("ì¶”ê°€ ë³´ì •: 4ë²ˆì§¸ ì—´ â†’ 2ë²ˆì§¸ ì—´ ë³µì‚¬(ë¬¸ìì—´)", step_copy_col4_to_col2_in_prefix_books),
    "types":        ("íƒ€ì…/ì œì¡°ì‚¬ ë³´ìœ  ìš”ì•½ ì¶œë ¥", step_summarize_types),
    "reports":      ("í•˜ìœ„ í´ë”ë³„ *_final_result_report.xlsx ìƒì„±", step_build_reports),
    "collect-total":("ëª¨ë“  ë¦¬í¬íŠ¸ í†µí•© (total_final_result.xlsx)", step_collect_total),

    # â˜… ì‹ ê·œ ë‹¨ê³„ ë“±ë¡
    "post-analyze": ("ìµœì¢… ê²°ê³¼ ì¶”ê°€ ë¶„ì„/ê°•ì¡° í‘œì‹œ", step_post_analyze_and_highlight),
}

DEFAULT_ORDER = [
    "resin",
    "zero",
    "group",
    "collect-avg",
    "copy-42",
    "types",
    "reports",
    "collect-total",
    # â˜… collect-total ì´í›„ ìë™ ì‹¤í–‰
    "post-analyze",
]


def run_steps(step_keys: Iterable[str], cfg: Config) -> int:
    env = setup_utf8_console_and_env()
    logger = Logger(cfg)

    print("ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ? í†µì‹ ì—°êµ¬ì†Œ ì†Œì† ê¹€í¬ì„œ ì—°êµ¬ì›ì…ë‹ˆë‹¤.")
    print("ê´‘ì„¬ìœ  íŠ¹ì„± ë¶„ì„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì§„í–‰í•˜ê¸° ìœ„í•´ í†µí•© íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
    print("ab.xlsxíŒŒì¼ - Draw ê³µì •ì‹¤ì  ì¡°íšŒ ê°’, alls.xlsxíŒŒì¼ - ì¸¡ì • ì‹¤ì  ì¡°íšŒ ê°’")
    print(f"[log] í™”ë©´+íŒŒì¼ ë™ì‹œ ê¸°ë¡: {logger.log_path}")
    print(f"=== íŒŒì´ì¬ ì‹¤í–‰ íŒŒì¼: {sys.executable}")
    print(f"=== ì‘ì—… ë””ë ‰í„°ë¦¬: {Path(__file__).resolve().parent}")
    print("=== ì‹¤í–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n")

    total = len(list(step_keys))
    executed = 0
    failed: List[Tuple[str, int]] = []

    for i, key in enumerate(step_keys, start=1):
        executed += 1
        title, fn = STEPS[key]
        tag = f"[{i}/{total}]"
        start_ts = time.perf_counter()
        print(f"{tag} {key} ì‹œì‘ | {title} | {datetime.now():%Y-%m-%d %H:%M:%S}")
        print("-" * 100)
        try:
            rc = fn(cfg)
        except Exception as e:  # pragma: no cover
            rc = 1
            print(f"[ì˜¤ë¥˜] ë‹¨ê³„ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸: {e}")
        elapsed = time.perf_counter() - start_ts
        print("-" * 100)
        status = "ì„±ê³µ" if rc == 0 else f"ì‹¤íŒ¨(rc={rc})"
        print(f"{tag} {key} ì¢…ë£Œ | {status} | ì†Œìš” {elapsed:.2f}s\n")

        if rc != 0:
            failed.append((key, rc))
            if cfg.stop_on_error:
                print(f"[ì¤‘ë‹¨] {key} ì‹¤íŒ¨ë¡œ ì´í›„ ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                break

    print("=== ì‹¤í–‰ ìš”ì•½ ===")
    print(f"- ì´ ìŠ¤í…: {total}")
    print(f"- ì„±ê³µ: {executed - len(failed)}")
    print(f"- ì‹¤íŒ¨: {len(failed)}")
    for name, rc in failed:
        print(f"  Â· {name}: rc={rc}")

    logger.close()
    return 0 if not failed else 1


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI  (â˜… ê³µí†µ ì˜µì…˜ì„ ë©”ì¸ íŒŒì„œì— ì¶”ê°€í•œ ë²„ì „)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_args(argv: Optional[List[str]] = None) -> argparse.Namespace:
    p = argparse.ArgumentParser(
        description="í†µí•© ê´‘ì„¬ìœ  ë°ì´í„° ë¶„ì„ íŒŒì´í”„ë¼ì¸",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    # âœ… ê³µí†µ ì˜µì…˜: ì–´ë–¤ ì„œë¸Œì»¤ë§¨ë“œ(run-all/run)ë¡œ ì‹¤í–‰í•˜ë“  nsì— í•­ìƒ ì¡´ì¬
    p.add_argument("--ab", dest="excel_ab", type=Path, default=CFG.excel_ab, help="ab.xlsx ê²½ë¡œ")
    p.add_argument("--alls", dest="excel_alls", type=Path, default=CFG.excel_alls, help="alls.xlsx ê²½ë¡œ")
    p.add_argument("--alls-cleaned", dest="excel_alls_cleaned", type=Path, default=CFG.excel_alls_cleaned, help="alls_cleaned.xlsx ê²½ë¡œ")
    p.add_argument("--out-prefix", dest="out_grouped_by_prefix", type=Path, default=CFG.out_grouped_by_prefix, help="grouped_by_prefix ì¶œë ¥ í´ë”")
    p.add_argument("--out-col4", dest="out_grouped_by_col4", type=Path, default=CFG.out_grouped_by_col4, help="grouped_by_col4 ì¶œë ¥ í´ë”")
    p.add_argument("--resin-col", dest="resin_col_idx", type=int, default=CFG.resin_col_idx, help="ab.xlsx ë ˆì§„ ì—´ ì¸ë±ìŠ¤(0-based)")
    p.add_argument("--drawno-col", dest="drawno_col_idx", type=int, default=CFG.drawno_col_idx, help="ab.xlsx draw_no ì—´ ì¸ë±ìŠ¤(0-based)")
    p.add_argument("--col3", dest="col3_idx", type=int, default=CFG.col3_idx, help="alls_cleaned.xlsx 3ë²ˆì§¸ ì—´ ì¸ë±ìŠ¤(0-based)")
    p.add_argument("--col4", dest="col4_idx", type=int, default=CFG.col4_idx, help="alls_cleaned.xlsx 4ë²ˆì§¸ ì—´ ì¸ë±ìŠ¤(0-based)")
    p.add_argument("--use-wpattern-first", action="store_true", help="ì ‘ë‘ ì¶”ì¶œ ì‹œ W-íŒ¨í„´ ìš°ì„ ")
    p.add_argument("--no-second-last-zero-filter", action="store_true", help="Cì—´ì˜ ë’¤ì—ì„œ 2ë²ˆì§¸=0 í•„í„° ë¹„í™œì„±í™”")
    p.add_argument("--no-stop-on-error", action="store_true", help="ì˜¤ë¥˜ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰")

    sub = p.add_subparsers(dest="cmd")

    # run-all (ê¸°ë³¸ ìˆœì„œ ì „ì²´ ì‹¤í–‰)
    sub.add_parser("run-all", help="ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")

    # ê°œë³„/ë³µìˆ˜ ë‹¨ê³„ ì‹¤í–‰: positional ë¡œ ë‹¨ê³„ í‚¤ ë‚˜ì—´
    sp_some = sub.add_parser("run", help="ì§€ì •í•œ ë‹¨ê³„ë§Œ ì‹¤í–‰")
    sp_some.add_argument("steps", nargs="+", choices=list(STEPS.keys()), help="ì‹¤í–‰í•  ë‹¨ê³„ í‚¤(ì—¬ëŸ¬ ê°œ ì§€ì • ê°€ëŠ¥)")

    # ê¸°ë³¸ì€ run-allë¡œ ë™ì‘
    p.set_defaults(cmd="run-all")
    return p.parse_args(argv)


def args_to_config(ns: argparse.Namespace) -> Config:
    cfg = Config(
        excel_ab=ns.excel_ab,
        excel_alls=ns.excel_alls,
        excel_alls_cleaned=ns.excel_alls_cleaned,
        out_grouped_by_prefix=ns.out_grouped_by_prefix,
        out_grouped_by_col4=ns.out_grouped_by_col4,
        resin_col_idx=ns.resin_col_idx,
        drawno_col_idx=ns.drawno_col_idx,
        col3_idx=ns.col3_idx,
        col4_idx=ns.col4_idx,
        use_w_pattern_first=bool(ns.use_wpattern_first),
        filter_second_last_zero=not bool(ns.no_second_last_zero_filter),
        stop_on_error=not bool(ns.no_stop_on_error),
    )
    return cfg


def main(argv: Optional[List[str]] = None) -> int:
    ns = parse_args(argv)
    cfg = args_to_config(ns)

    if ns.cmd == "run-all":
        steps = DEFAULT_ORDER
    elif ns.cmd == "run":
        steps = ns.steps
    else:
        steps = DEFAULT_ORDER

    # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë‹¨ê³„ í‚¤ ë°©ì§€(ë°©ì–´)
    steps = [s for s in steps if s in STEPS]
    if not steps:
        print("[ì˜¤ë¥˜] ì‹¤í–‰í•  ë‹¨ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return 1

    return run_steps(steps, cfg)


if __name__ == "__main__":
    raise SystemExit(main())
